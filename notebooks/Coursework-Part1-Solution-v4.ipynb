{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Coursework Part 1 (Solution): Detecting Spam with Spark\n\nThese are model answers for the IN432 Big Data coursework 2018, part 1.  \n\nThis coursework is about classification of e-mail messages as spam or non-spam in Spark. We will go through the whole process from loading preprocessing to training and testing classifiers in a distributed way in Spark. We wil use the techniques shown in the lextures and labs. I will also introduce here a few additional elements, such as the NLTK and some of the preprocessing and machine learning functions that come with Spark. You are not expected to need anything beyond the material handed out so far and in some cases the Spark documentation, to which I have put links in this document.  \n\nThe structure is similar to the lab sheets. I provide a code structure with gaps that you are supposed to file. In addition you should run 2 small experiments and comment on the results. The lines where you are supposed to add code or take another action are marked with \">>>\" \nplease leave the \">>>\" in the text, comment out that line, and write your own code in the next line using a copy of that line as a starting point.\n\nI have added numerous comments in text cells and the code cells to guid you through the program. Please read them carefully and ask if anything is unclear. \n\nOnce you have completed the tasks, don't delete the outpus, but downlaod the notebook (outputs will be included) and upload it into the coursework submission area on Moodle. The coursework part counts for 25% or the total coursework.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Load and prepare the data\n\nWe will use the lingspam dataset in this coursework (see [http://csmining.org/index.php/ling-spam-datasets.html](http://csmining.org/index.php/ling-spam-datasets.html) for more information).\n\nThe next cell is only needed if you haven't cloned the repository in week 2 or later (but it doesn't do harm to run it). ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# go to the work directory \n%cd ~/notebook/work/\n# and clone the project from github\n!git clone https://github.com/tweyde/City-Data-Science.git", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "# now that we have the project directory\n%cd ~/notebook/work/City-Data-Science/\n# we can pull the latest files\n!git pull\n#we need to use a magic command (starting with '%') here, to change the directory\n%cd ./datasets/ \nprint(\">>> Extracting the ling_spam dataset, this can take a moment.\")\n# '!' calls a program on the machine (the DSX service runs on Linux machines). \n!tar -xf lingspam_public02.tar.gz\nprint(\">>> Unzipping finished.\")\n# We now have a new dataset in directory 'bare'.\n%cd lingspam_public/bare \nprint(\">>> pwd \")\n!pwd\nprint(\">>> ls \")\n# the line before last of output should show \"part1 part10 part2  part3  part4  part5  part6  part7 part8 part9\"\n!ls\n# finally we return to the 'lingspam_public' directory\n%cd ..", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "### Tools for Troubleshooting\n\nNormally, DSX works reliably, but there are two issues that have occured. We have solutions for them that you can use with the following cells. \nIf other problems occur, reloading the page and/or restarting the Kernel can help. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# try this in case of \"sc undefined\" or similar errors, should normally not be necessary.\nfrom pyspark import SparkContext \nsc = spark.sparkContext ", 
            "cell_type": "code", 
            "execution_count": 25, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "# Sometimes you may get an error that the metastore_db is not accessible, especially when you have multiple notebooks open at the same time.\n# We can not prevent this form happening on DSX.\n# If it does happen you need to delete the metastore_db. \n# The path of the metastore_db is in the error messages and it's typically long like this example: \n# /gpfs/global_fs01/sym_shared/YPProdSpark/user/s832-dfe96c6e1f1d61-70d619a53771/notebook/jupyter-rt/kernel-cdcf5f73-9afb-481d-ac40-a210a649eb69-20180222_154448/metastore_db\n# once you have it, you can use it with !rm -Rf to delete it (replace the term in <> with the path you get from your error message):\n!rm -Rf <Put the path of the metastore_db here>", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "# Task 1) Read the dataset and create RDDs \na) Start by reading the directory with text files from the file system (`~/notebook/work/City-Data-Science/datasets/bare`). Load all text files per dirctory (part1,part2, ... ,part10) using `wholeTextFiles()`, which creates one RDD per part, containing tuples (filename,text). This is a good choice as the text files are small. (5%)\n\nb) We will use one of the RDDs as test set, the rest as training set. For the training set you need to create the union of the remaining RDDs. (5%)\n\nb) Remove the path and extension from the filename using the regular expression provided (5%).\n\nIf the filename starts with 'spmsg' it is spam, otherwise it is not. We'll use that later to train a classifier. \n\nWe will put the code in each cell into a function that we can reuse later. In this way we can develop the whole preprocessing with the smaller test set and apply it to the training set once we know that everything works. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "from pathlib import Path\nimport os.path\nimport re\n\ndef makeTestTrainRDDs(pathString):\n    \"\"\" Takes one of the four subdirectories of the lingspam dataset and returns two RDDs one each for testing and training. \"\"\"\n    # We should see10 parts that we can use for creating train and test sets.\n    p = Path(pathString) # gets a path object representing the current directory path.\n    dirs = list(p.iterdir()) # get the directories part1 ... part10. \n    rddList = [] # create a list for the RDDs\n    # now create an RDD for each 'part' directory and add them to rddList\n    for d in dirs: # iterate through the directories\n        rdd = sc.wholeTextFiles(str(d.absolute())) #>>> # read the files in the directory \n        rddList.append(rdd) #>>> append the RDD to the list\n    #print('len(rddList)',len(rddList))  # we should now have 10 RDDs in the list # just for testing\n    #print(rddList[1].take(1)) # just for testing, comment out when it works.\n    testRDD1 = rddList[9] # set the test set\n    trainRDD1 = rddList[0] # start the training set from 0 and \n    # now loop over the range from 1 to 9(exclusive) to create a union of the remaining RDDs\n    for i in range(1,9):\n        trainRDD1 = trainRDD1.union(rddList[i]) #>>> create a union of the current and the next \n            # RDD in the list, so that in the end we have a union of all parts 0-8. (9 ist used as test set)\n    # both RDDs should remove the paths and extensions from the filename. \n    # This regular expression will do it: re.split('[/\\.]', fn_txt[0])[-2]\n    #>>> apply it to the filenames in train and test RDD with a lambda\n    testRDD2 = testRDD1.map(lambda fn_txt: (re.split('[/\\.]', fn_txt[0])[-2], fn_txt[1])) # >>>\n    trainRDD2 = trainRDD1.map(lambda fn_txt: (re.split('[/\\.]', fn_txt[0])[-2], fn_txt[1])) # >>>\n    return (trainRDD2,testRDD2)\n\n# dictionary for caching RDDs for multiple use\ntmp1 = {} \n\n# This is a different version, which creates the training RDD in one operation using glob expressions instead of a union of RDDs and caching\ndef makeTestTrainRDDs2(pathString):\n    \"\"\" Takes one of the four subdirectories of the lingspam dataset and returns two RDDs one each for testing and training. \n    It caches the data RDDs, so that within one process they do not need   \"\"\" \n    if pathString not in tmp1:\n        # We should see10 parts that we can use for creating train and test sets\n        absPath = os.path.abspath(pathString)\n        testRDD1 = sc.wholeTextFiles(absPath+'/part10/')\n        trainRDD1 = sc.wholeTextFiles(absPath+'/part[1-9]/')\n        # both RDDs should remove the paths and extensions from the filename. \n        # This regular expression will do it: re.split('[/\\.]', fn_txt[0])[-2]\n        #>>> apply it to the filenames in train and test RDD with a lambda\n        testRDD2 = testRDD1.map(lambda fn_txt: (re.split('[/\\.]', fn_txt[0])[-2], fn_txt[1])) # >>>\n        trainRDD2 = trainRDD1.map(lambda fn_txt: (re.split('[/\\.]', fn_txt[0])[-2], fn_txt[1])) # >>>\n        testRDD2.cache()\n        testRDD2.cache()\n        tmp1[pathString] = (trainRDD2,testRDD2)\n    return tmp1[pathString]\n\n\n# this makes sure we are in the right directory\n%cd ~/notebook/work/City-Data-Science/datasets/lingspam_public/\n# this should show \"bare  lemm  lemm_stop  readme.txt  stop\"\n!ls\n# the code below is for testing the function makeTestTrainRDDs\ntrainRDD_testRDD = makeTestTrainRDDs('bare') # read from the 'bare' directory - this takes a bit of time\n(trainRDD,testRDD) = trainRDD_testRDD # unpack the returned tuple\nprint('created the RDDs') # notify the user, so that we can figure out where things went wrong if they do.\nprint('testRDD.count(): ',testRDD.count()) # should be ~290 \n#print('trainRDD.count(): ',trainRDD.count()) # should be ~2600 - commented out to save time\nprint('testRDD.getNumPartitions()',testRDD.getNumPartitions()) # normally 2 on DSX\nprint('testRDD.getStorageLevel()',testRDD.getStorageLevel()) # Serialized 1x Replicated on DSX\nprint('testRDD.take(1): ',testRDD.take(1)) # should be (filename,[tokens]) \n\nrdd1 = testRDD # use this for developemnt in the next tasks ", 
            "cell_type": "code", 
            "execution_count": 1, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "/gpfs/global_fs01/sym_shared/YPProdSpark/user/s832-dfe96c6e1f1d61-70d619a53771/notebook/work/City-Data-Science/datasets/lingspam_public\nbare  lemm  lemm_stop  readme.txt  results1.pkl  results2.pkl  stop\ncreated the RDDs\ntestRDD.count():  291\ntestRDD.getNumPartitions() 2\ntestRDD.getStorageLevel() Serialized 1x Replicated\ntestRDD.take(1):  [('9-66msg1', \"Subject: xth conference of nordic and general ling .\\n\\nthe tenth conference of nordic and general linguistics will be held in reykjavik , iceland , from saturday june 6 , to monday june 8 , 1998 . it is organized by the institute of linguistics , university of iceland . the deadline for pre-registration at a reduced price is january 31 , 1998 . pre - registration forms and further information can be found on our web site ( http : / / www . rhi . hi . is / ~ nordconf ) and can also be mailed or e-mailed upon request . papers on any linguistic topic are invited , especially papers on synchronic and diachronic aspects of the nordic languages . invited speakers : anders holmberg , tromsoe ( syntax ) tomas riad , stockholm ( phonology ) inge lise pedersen , copenhagen ( dialectology ) interest groups can ask to arrange special sessions ( workshops ) and at present the following are planned ( names of the workshop organizers in parentheses ) : comparative semantics for nordic languages ( elisabet engdahl ) optimality theory and nordic languages ( kersti boerjars ) the time allotted to each paper ( except for the invited talks ) is 30 minutes ( including discussion ) . participants who want to present a paper are requested to submit an abstract no later than january 31 , 1998 . abstracts may not exceed 2 pages with at least a 1 inch margin on all four sides and should employ a font not smaller than 12 pt . they should be sent anonymously in five copies , accompanied by a camera-ready original with the author 's name , address and affiliation . abstracts sent by e-mail will not be accepted . the authors will be notified about the acceptance of their papers by february 28 , 1998 . those interested in presenting papers in the special sessions ( workshops ) should consult the organizers of these ( engdahl @ ling . gu . se , k . borjars @ man . ac . uk ) . otherwise , correspondence should be addressed to : the xth conference of nordic and general linguistics institute of linguistics university of iceland arnagardi vid sudurgoetu \\\\ 193rnagar \\\\ 240i vi \\\\ 240 su \\\\ 240urg \\\\ 246tu 101 reykjavik , iceland tel . + 354 525 4408 fax + 354 525 4242 e - mail : nordconf @ rhi . hi . is url : http : / / www . rhi . hi . is / ~ nordconf - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - h \\\\ 246skuldur \\\\ 222r \\\\ 225insson hoskuldur thrainsson heimspekideild department of icelandic h \\\\ 225sk \\\\ 243la \\\\ 205slands university of iceland \\\\ 193rnagar \\\\ 240i v . su \\\\ 240urg \\\\ 246tu arnagardi v . sudurgoetu 101 reykjavik 101 reykjavik , iceland netfang : hoski @ rhi . hi . is e-mail hoski @ rhi . hi . is simi : 525-4420 ( i vinnu ) phone : ( 354 ) 525-4420 ( office ) 566-7141 ( heima ) ( 354 ) 566-7141 ( home ) br \\\\ 233fsimi : 525-4242 ( i vinnu ) fax : ( 354 ) 525-4242 ( work ) 566-8141 ( heima - ( 354 ) 566-8141 ( home - ef l \\\\ 225ti \\\\ 240 er vita fyrirfram ) if notified in advance )\\n\")]\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "### Task 2) Tokenize and remove punctuation\n\nNow we need to split the words, a process called *tokenization* by linguists, and remove punctuation. \n\nWe will use the Python [Natural Language Toolkit](http://www.nltk.org) *NLTK* to do the tokenization (rather than splitting ourselves, as these specialist tools usually do that better than we can ourselves). We use the NLTK function word_tokenize, see here for a code example: [http://www.nltk.org/book/ch03.html](http://www.nltk.org/book/ch03.html). (5%)\n\nThen we will remove punctuation. There is no specific funtion for this, so we use a regular expression (see here for info [https://docs.python.org/3/library/re.html?highlight=re#module-re](https://docs.python.org/3/library/re.html?highlight=re#module-re)) in a list comprehension (here's a nice visual explanation: [http://treyhunner.com/2015/12/python-list-comprehensions-now-in-color/](http://treyhunner.com/2015/12/python-list-comprehensions-now-in-color/)). (5%) \n\nWe use a new technique here: we separate keys and values of the RDD, using the RDD functions `keys()` and `values()`, which yield each a new RDD. Then we process the values and *zip* them together with the keys again. See here for documentation: [http://spark.apache.org/docs/2.1.0/api/python/pyspark.html#pyspark.RDD.zip](http://spark.apache.org/docs/2.1.0/api/python/pyspark.html#pyspark.RDD.zip).  We wrap the whole sequence into one function `prepareTokenRDD` for later use. (5%)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "import nltk    \nimport re\nfrom nltk.corpus import stopwords\n\ndef tokenize(text):\n    \"\"\" Apply the nltk.word_tokenize() method to our text, return the token list. \"\"\"\n    nltk.download('punkt') # this loads the standard NLTK tokenizer model \n    # it is important that this is done here in the function, as it needs to be done on every worker.\n    # If we do the download outside a this function, it would only be executed on the driver     \n    return nltk.word_tokenize(text) # >>> use the nltk function word_tokenize\n    \ndef removePunctuation(tokens):\n    \"\"\" Remove punctuation characters from all tokens in a provided list. \"\"\"\n    tokens2 =  [re.sub('[()\\[\\],.?!\";_]','',token) for token in tokens] # use a list comprehension to remove punctuaton\n    return tokens2\n\ndef prepareTokenRDD(fn_txt_RDD):\n    \"\"\" Take an RDD with (filename,text) elements and transform it into a (filename,[token ...]) RDD without punctuation characters. \"\"\"\n    rdd_vals2 = fn_txt_RDD.values() # It's convenient to process only the values. \n    rdd_vals3 = rdd_vals2.map(tokenize) # Create a tokenised version of the values by mapping (we could have done that in palce with a lambda)\n    rdd_vals4 = rdd_vals3.map(removePunctuation) # remove punctuation from the values (could also have been a lambda)\n    rdd4 = fn_txt_RDD.keys().zip(rdd_vals4) # we zip the two RDDs together \n    # i.e. produce tuples with one item from each RDD.\n    # This works because we have only applied mappings to the values, \n    # therefore the items in both RDDs are still aligned.\n    # >>> now remove any empty strings (i.e. length 0) that we may have \n    # created by removing punctuation, and resulting entries without words left.\n    rdd5 = rdd4.map(lambda kv: (kv[0],[s for s in kv[1] if len(s)>0])) # remove empty words using RDD.map and a lambda. \n    rdd6 = rdd5.filter(lambda kv: len(kv[0])>0) # remove empty items using RDD.filter and a lambda. \n    # >>> Question: why should this filtering be done after zipping the keys and values together?\n    return rdd6 \n\nrdd2 = prepareTokenRDD(rdd1) # Use the test set for now, because it is smaller\nprint(rdd2.take(1)) #  checking result of task 2. \n# The output should looks something like: \"[('9-66msg1', ['Subject', ':', 'xth', 'conference', 'of', 'nordic', 'and', 'general', 'ling', ... \"", 
            "cell_type": "code", 
            "execution_count": 2, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "[('9-66msg1', ['Subject', ':', 'xth', 'conference', 'of', 'nordic', 'and', 'general', 'ling', 'the', 'tenth', 'conference', 'of', 'nordic', 'and', 'general', 'linguistics', 'will', 'be', 'held', 'in', 'reykjavik', 'iceland', 'from', 'saturday', 'june', '6', 'to', 'monday', 'june', '8', '1998', 'it', 'is', 'organized', 'by', 'the', 'institute', 'of', 'linguistics', 'university', 'of', 'iceland', 'the', 'deadline', 'for', 'pre-registration', 'at', 'a', 'reduced', 'price', 'is', 'january', '31', '1998', 'pre', '-', 'registration', 'forms', 'and', 'further', 'information', 'can', 'be', 'found', 'on', 'our', 'web', 'site', 'http', ':', '/', '/', 'www', 'rhi', 'hi', 'is', '/', '~', 'nordconf', 'and', 'can', 'also', 'be', 'mailed', 'or', 'e-mailed', 'upon', 'request', 'papers', 'on', 'any', 'linguistic', 'topic', 'are', 'invited', 'especially', 'papers', 'on', 'synchronic', 'and', 'diachronic', 'aspects', 'of', 'the', 'nordic', 'languages', 'invited', 'speakers', ':', 'anders', 'holmberg', 'tromsoe', 'syntax', 'tomas', 'riad', 'stockholm', 'phonology', 'inge', 'lise', 'pedersen', 'copenhagen', 'dialectology', 'interest', 'groups', 'can', 'ask', 'to', 'arrange', 'special', 'sessions', 'workshops', 'and', 'at', 'present', 'the', 'following', 'are', 'planned', 'names', 'of', 'the', 'workshop', 'organizers', 'in', 'parentheses', ':', 'comparative', 'semantics', 'for', 'nordic', 'languages', 'elisabet', 'engdahl', 'optimality', 'theory', 'and', 'nordic', 'languages', 'kersti', 'boerjars', 'the', 'time', 'allotted', 'to', 'each', 'paper', 'except', 'for', 'the', 'invited', 'talks', 'is', '30', 'minutes', 'including', 'discussion', 'participants', 'who', 'want', 'to', 'present', 'a', 'paper', 'are', 'requested', 'to', 'submit', 'an', 'abstract', 'no', 'later', 'than', 'january', '31', '1998', 'abstracts', 'may', 'not', 'exceed', '2', 'pages', 'with', 'at', 'least', 'a', '1', 'inch', 'margin', 'on', 'all', 'four', 'sides', 'and', 'should', 'employ', 'a', 'font', 'not', 'smaller', 'than', '12', 'pt', 'they', 'should', 'be', 'sent', 'anonymously', 'in', 'five', 'copies', 'accompanied', 'by', 'a', 'camera-ready', 'original', 'with', 'the', 'author', \"'s\", 'name', 'address', 'and', 'affiliation', 'abstracts', 'sent', 'by', 'e-mail', 'will', 'not', 'be', 'accepted', 'the', 'authors', 'will', 'be', 'notified', 'about', 'the', 'acceptance', 'of', 'their', 'papers', 'by', 'february', '28', '1998', 'those', 'interested', 'in', 'presenting', 'papers', 'in', 'the', 'special', 'sessions', 'workshops', 'should', 'consult', 'the', 'organizers', 'of', 'these', 'engdahl', '@', 'ling', 'gu', 'se', 'k', 'borjars', '@', 'man', 'ac', 'uk', 'otherwise', 'correspondence', 'should', 'be', 'addressed', 'to', ':', 'the', 'xth', 'conference', 'of', 'nordic', 'and', 'general', 'linguistics', 'institute', 'of', 'linguistics', 'university', 'of', 'iceland', 'arnagardi', 'vid', 'sudurgoetu', '\\\\', '193rnagar', '\\\\', '240i', 'vi', '\\\\', '240', 'su', '\\\\', '240urg', '\\\\', '246tu', '101', 'reykjavik', 'iceland', 'tel', '+', '354', '525', '4408', 'fax', '+', '354', '525', '4242', 'e', '-', 'mail', ':', 'nordconf', '@', 'rhi', 'hi', 'is', 'url', ':', 'http', ':', '/', '/', 'www', 'rhi', 'hi', 'is', '/', '~', 'nordconf', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'h', '\\\\', '246skuldur', '\\\\', '222r', '\\\\', '225insson', 'hoskuldur', 'thrainsson', 'heimspekideild', 'department', 'of', 'icelandic', 'h', '\\\\', '225sk', '\\\\', '243la', '\\\\', '205slands', 'university', 'of', 'iceland', '\\\\', '193rnagar', '\\\\', '240i', 'v', 'su', '\\\\', '240urg', '\\\\', '246tu', 'arnagardi', 'v', 'sudurgoetu', '101', 'reykjavik', '101', 'reykjavik', 'iceland', 'netfang', ':', 'hoski', '@', 'rhi', 'hi', 'is', 'e-mail', 'hoski', '@', 'rhi', 'hi', 'is', 'simi', ':', '525-4420', 'i', 'vinnu', 'phone', ':', '354', '525-4420', 'office', '566-7141', 'heima', '354', '566-7141', 'home', 'br', '\\\\', '233fsimi', ':', '525-4242', 'i', 'vinnu', 'fax', ':', '354', '525-4242', 'work', '566-8141', 'heima', '-', '354', '566-8141', 'home', '-', 'ef', 'l', '\\\\', '225ti', '\\\\', '240', 'er', 'vita', 'fyrirfram', 'if', 'notified', 'in', 'advance'])]\n"
                }
            ], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "source": "### Task 3) Creating normalised TF.IDF vectors of defined dimensionality, measure the effect of caching.\n\nWe use the hashing trick to create fixed size TF vectors directly from the word list now (slightly different from the previous lab, where we used *(word,count)* pairs.). Write a bit of code as needed. (5%)\n\nThen we'll use the IDF and Normalizer functions provided by Spark. They use a slightly different pattern than RDD.map and reduce, have a look at the examples here in the documentation for Normalizer  and IDF:\n[http://spark.apache.org/docs/2.1.0/api/python/pyspark.mllib.html#pyspark.mllib.feature.Normalizer](http://spark.apache.org/docs/2.1.0/api/python/pyspark.mllib.html#pyspark.mllib.feature.Normalizer), [http://spark.apache.org/docs/2.1.0/api/python/pyspark.mllib.html#pyspark.mllib.feature.IDF](http://spark.apache.org/docs/2.1.0/api/python/pyspark.mllib.html#pyspark.mllib.feature.IDF) (5%)\n\nWe want control of the dimensionality in the `normTFIDF` function, so we introduce an argument into our functions that enables us to vary dimensionalty later. Here is also an opportunity to benefit from caching, i.e. persisting the RDD after use, so that it will not be recomputed.  (5%)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# use the hashing trick to create a fixed-size vector from a word list\ndef hashing_vectorize(text,N): # arguments: the list and the size of the output vector\n    v = [0] * N  # create vector of 0s\n    for word in text: # iterate through the words \n        h = hash(word)          # get the hash value \n        v[h % N] = v[h % N] + 1 # add 1 at the hashed address \n    return v # return hashed word vector\n\nfrom pyspark.mllib.feature import IDF, Normalizer\n\ntmp2 = {}\ndef normTFIDF(fn_tokens_RDD, vecDim, caching=True):\n    keysRDD = fn_tokens_RDD.keys()\n    tokensRDD = fn_tokens_RDD.values()\n    tfVecRDD = tokensRDD.map(lambda tokens: hashing_vectorize(tokens,vecDim)) #>>> passing the vecDim value. TIP: you need a lambda. \n    if caching:\n        tfVecRDD.persist(StorageLevel.MEMORY_ONLY) # since we will read more than once, caching in Memory will make things quicker.\n    idf = IDF()\n    idfModel = idf.fit(tfVecRDD)\n    tfIdfRDD = idfModel.transform(tfVecRDD)\n    norm = Normalizer()\n    normTfIdfRDD = norm.transform(tfIdfRDD)\n    zippedRDD = keysRDD.zip(normTfIdfRDD)\n    return zippedRDD\n\ntestDim = 10 # too small, but good for testing\nrdd3 = normTFIDF(rdd2, testDim, True) # apply task2\nprint(rdd3.take(10)) # we should now have tuples with ('filename',[N-dim vector])\n# e.g. [('9-1142msg1', DenseVector([0.0, 0.0, 0.0, 0.0, 0.4097, 0.0, 0.0, 0.0, 0.9122, 0.0]))]", 
            "cell_type": "code", 
            "execution_count": 3, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "[('9-66msg1', DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0])), ('9-751msg1', DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0])), ('spmsgc6', DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0])), ('9-628msg1', DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0])), ('9-976msg1', DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0])), ('9-973msg1', DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0])), ('9-839msg1', DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0])), ('9-709msg1', DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0])), ('9-922msg1', DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0])), ('9-842msg1', DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]))]\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "## Comment:\nThe zeros here appear because the log(IDF) values will be 0 for many dimensions. This occurs because we calculate the Hashing Vector before we calculate the IDF valuest. This is more efficient than calculating TF.IDF first, but leads to quicker degradation when the vector dimensions are small. This makes finding an appropriate vector size even more important. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#### Task 3a) Caching experiment\n\nThe normTFIDF let's us switch caching on or off. Write a bit of code that measures the effect of caching by takes the time for both options. Use the time function as shown in lecture 3, slide 47. Remember that you need to call an action on an RDD to trigger full execution. \n\nAdd a short comment on the result (why is there an effect, why of the size that it is?). Remember that this is wall clock time, i.e. you may get noisy results. (10%)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#run a small experiment with caching set to True or False, 3 times each\n\nfrom time import time\n\nresCaching = [] # for storing results\nresNoCache = []\nfor i in range(3): # 3 samples\n    startTime = time() # start timer\n    testRDD1 = normTFIDF(rdd2, testDim, True) # \n    testRDD1.collect() # needed to force execution\n    endTime = time()\n    resCaching.append( endTime - startTime )\n    \n    startTime = time()\n    testRDD2 = normTFIDF(rdd2, testDim, False) \n    testRDD2.collect() # needed to force execution   \n    endTime = time()\n    resNoCache.append( endTime - startTime )\n    \nmeanTimeCaching = sum(resCaching)/len(resCaching)\nmeanTimeNoCache = sum(resNoCache)/len(resNoCache)\n\nprint('Creating TF.IDF vectors, 3 trials - mean time with caching: ', meanTimeCaching, ', mean time without caching: ', meanTimeNoCache)", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "## Comment\nMy results are:\n`Creating TF.IDF vectors, 3 trials - mean time with caching:  15.675768772761026 , mean time without caching:  22.62595049540202`\n\nThis shows that caching speeds up the processing. This is because the calculations and reading from disk would have to \nbe preformed again for 2nd use if there is no cache. Persistence means that the 2nd time round we can read stored valued from memory. \nThis is very effective here, as the RDD is small and will fit into memory. \nThere are two times that tfVecRDD is read when the IDF is calculated and applied, by persisting (caching) we calculate it only once, which reduces the time taken by about 30%.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Task 4) Create LabeledPoints \n\nDetermine whether the file is spam (i.e. the filename contains \u2019spmsg\u2019) and replace the filename by a 1 (spam) or 0 (non-spam) accordingly. Use `RDD.map()` to create an RDD of LabeledPoint objects. See here [http://spark.apache.org/docs/2.1.0/mllib-linear-methods.html#logistic-regression](http://spark.apache.org/docs/2.1.0/mllib-linear-methods.html#logistic-regression) for an example, and here [http://spark.apache.org/docs/2.1.0/api/python/pyspark.mllib.html#pyspark.mllib.regression.LabeledPoint](http://spark.apache.org/docs/2.1.0/api/python/pyspark.mllib.html#pyspark.mllib.regression.LabeledPoint) for the `LabeledPoint` documentation. (10%)\n\nThere is a handy function of Python strings called startswith: e.g. 'abc'.startswith('ab) will return true. The relevant Python syntax here is a conditional expression: **``<a> if <yourCondition> else <b>``**, i.e. 1 if the filename starts with 'spmsg' and otherwise 0.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "from pyspark.mllib.regression import LabeledPoint\n\n# creatate labelled points of vector size N out of an RDD with normalised (filename [(word,count), ...]) items\ndef makeLabeledPoints(fn_vec_RDD): # RDD and N needed \n    # we determine the true class as encoded in the filename and represent as 1 (samp) or 0 (good)\n    cls_vec_RDD = fn_vec_RDD.map(lambda fn_vec: (1 if fn_vec[0].startswith('spmsg') else 0,fn_vec[1])) \n    # now we can create the LabeledPoint objects with (class,vector) arguments\n    lp_RDD = cls_vec_RDD.map(lambda cls_vec: LabeledPoint(cls_vec[0],cls_vec[1]) ) \n    return lp_RDD \n\n# for testing\ntestLpRDD = makeLabeledPoints(rdd3) \nprint(testLpRDD.take(1)) \n# should look like this: [LabeledPoint(0.0, [0.0,0.0,0.0,0.0,0.40968062880166006,0.0,0.0,0.0,0.9122290186048,0.0])]", 
            "cell_type": "code", 
            "execution_count": 31, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "[LabeledPoint(0.0, [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.012736603569842138,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.022145734121861216,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.015008921926629391,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.013356428624859975,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.014571310671296732,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.031132612242499597,0.0,0.0,0.0,0.0,0.033358503557829565,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0315609538306996,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.014571310671296732,0.0,0.0,0.0,0.01741438691852247,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08720314787665039,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01374628930183428,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02439393551208377,0.0,0.0,0.0,0.0,0.0,0.0038580829233091393,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02439393551208377,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.011380695142373252,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.018705607496972403,0.0,0.0,0.011170492581712864,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.10684839755822446,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.030612388505521945,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06364892871524264,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04164708919840836,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.034216560352870816,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05342419877911223,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04429146824372243,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03856314108803714,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.017703009360026303,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0272422700255919,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.10327625097568062,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.21702627055672585,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04599366993357469,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.039994595896638944,0.0,0.0,0.0,0.0,0.0,0.04599366993357469,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.035149321193200696,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.025523398882538156,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.033358503557829565,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05342419877911223,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04599366993357469,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.022133834042433853,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.039994595896638944,0.0,0.0,0.0,0.01520352895284355,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02273517924327553,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02475735970928116,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.049077618043945906,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01610534987150498,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.035149321193200696,0.0,0.0,0.0,0.0,0.0,0.0,0.05973995923540897,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.019978232678534623,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04599366993357469,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.011275078651434855,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.049077618043945906,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09198733986714938,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.015621659386601183,0.0,0.0,0.0,0.04599366993357469,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.008034631599350478,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02370208339696205,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04371970171343418,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.009181371342789327,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.030017843853258782,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.026208363991549154,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.017703009360026303,0.0,0.0,0.0,0.0,0.0,0.017896167506876115,0.0,0.02592797471229202,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.039994595896638944,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.009376409238493096,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05543758469532631,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06364892871524264,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.013484813238587178,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.049077618043945906,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01169168394381097,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.032564067051101396,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.036171045092787645,0.0,0.0,0.004000430194681049,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.010762062720956983,0.0,0.0,0.0,0.0,0.007479927472350638,0.0,0.003641630093166419,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.10684839755822446,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.017143578758365665,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04599366993357469,0.0,0.0,0.026786031507333264,0.0,0.018201696571689543,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.12494126759522507,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.023372211612496824,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.049077618043945906,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04108992205795503,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0272422700255919,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.045482884420628714,0.0162715545514245,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.021045282912867603,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.018440254320920745,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.018260168538324587,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.014014302939375561,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.011170492581712864,0.0,0.0,0.0,0.0,0.1308047218149756,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02185985085671709,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.030482717077676278,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03730050846324203,0.0,0.0,0.0,0.0,0.0,0.08720314787665039,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2944657082636754,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.049077618043945906,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01322956339135169,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1999729794831947,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04599366993357469,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.034216560352870816,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.030930320889776052,0.0,0.0,0.020229411279986977,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.012857734656588059,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.035441654618233905,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.035149321193200696,0.0,0.0,0.0,0.01531091336477681,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01751327012155076,0.0,0.032564067051101396,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07998919179327789,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.020288263502125606,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.027718792347663154,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.008430247974243797,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.012037226015930049,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.018092870037000608,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.011376387679629046,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.049077618043945906,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.036171045092787645,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02370208339696205,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02821748631593507,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.010762062720956983,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01849744586675447,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.039994595896638944,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.016440376735231195,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03428715751673133,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04360157393832519,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.018293249462073394,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.039994595896638944,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.028740516247250103,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.016382261082127272,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.011851799558644857,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.21369679511644893,0.0,0.0,0.0,0.05342419877911223,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01531091336477681,0.0,0.0,0.0,0.03182446435762132,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04599366993357469,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0094759142649366,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08720314787665039,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03182446435762132,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.014014302939375561,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.009355683917044659,0.049077618043945906,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03465366172748723,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0474041667939241,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.025523398882538156,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01036862454115734,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.006483750455305096,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09815523608789181,0.0,0.0,0.0,0.0,0.0,0.026348420252000605,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01849744586675447,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01958119493715782,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03783578281292612,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.011275078651434855,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.025523398882538156,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01428918946518986,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.014014302939375561,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.049077618043945906,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.013356428624859975,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04599366993357469,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.002878481967414788,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.007357354587924229,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.022439450772166938,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01913446416862811,0.0,0.034699284103869736,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.004218851717997237,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01428918946518986,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.008006734669291847,0.0,0.0,0.0,0.0,0.0,0.02475735970928116,0.0,0.0,0.0,0.04157391494079504,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.032543109102849,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.026786031507333264,0.0,0.025473207139684276,0.0,0.0,0.0,0.0,0.0,0.08720314787665039,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.022439450772166938,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.044878901544333875,0.0,0.0,0.09198733986714938,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01891789140646306,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.005978302486740489,0.0,0.0,0.0,0.0,0.0,0.017703009360026303,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.034216560352870816,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04599366993357469,0.0,0.015941682766959276,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0272422700255919,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.017326830863743616,0.0,0.0,0.0,0.0,0.029290379702254638,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.006054284393049631,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03392681333309245,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01531091336477681,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.012980250128577286,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.034216560352870816,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.049077618043945906,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.036171045092787645,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02886775604899632,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04164708919840836,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.014861057691075093,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01036862454115734,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03062182672955362,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.013356428624859975,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2759620196014481,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02592797471229202,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09815523608789181,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03645199827486082,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.004218851717997237,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5376596331186808,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.049077618043945906,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.014715205276323667,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.016786212762582204,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09815523608789181,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03182446435762132,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.029290379702254638,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.010465638661338567,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.012857734656588059,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.035149321193200696,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05185594942458404,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08720314787665039,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.016786212762582204,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.006382138297581062,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.018092870037000608,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.021309987401712555,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04360157393832519,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09815523608789181,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.014677741306609884,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.035149321193200696,0.0,0.0,0.0,0.0029779656933370986,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.017703009360026303,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05342419877911223,0.0,0.0,0.0,0.0,0.03182446435762132,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04951471941856232,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04164708919840836,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04371393201389019,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02553346176426519,0.0,0.010272480514488758,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04599366993357469,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.030930320889776052,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01891789140646306,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.10684839755822446,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.032564067051101396,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.011066917021216927,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.017143578758365665,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.021045282912867603,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.017703009360026303,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.004383356027207089,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1999729794831947,0.0,0.0])]\n"
                }
            ], 
            "metadata": {
                "pixiedust": {
                    "displayParams": {
                        "handlerId": "tableView"
                    }
                }
            }
        }, 
        {
            "source": "### Complete the preprocessing (no task, but read it)\n\nIt will be useful to have a single function to do the preprocessing. Se integrate everything here.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# now we can apply the preprocessing chain to the data loaded in task 1 \n# N is for controlling the vector size\ndef preprocess(rawRDD,N):\n    \"\"\" take a (filename,text) RDD and transform into LabelledPoint objects \n        with class labels and a TF.IDF vector with N dimensions. \n    \"\"\"\n    tokenRDD = prepareTokenRDD(rawRDD) # task 2\n    tfIdfRDD = normTFIDF(tokenRDD,N) # task 3\n    lpRDD = makeLabeledPoints(tfIdfRDD) # task 4\n    return lpRDD # return RDD with LabeledPoints\n\n# and with this we can start the whole process from a directory, N is again the vector size\ndef loadAndPreprocess(directory,N):\n    \"\"\" load lingspam data from a directory and create a training and test set of preprocessed data \"\"\"\n    trainRDD_testRDD = makeTestTrainRDDs(directory) # read from the directory \n    (trainRDD,testRDD) = trainRDD_testRDD # unpack the returned tuple\n    return (preprocess(trainRDD,N),preprocess(testRDD,N))\n\ntrainLpRDD = preprocess(trainRDD,testDim) # prepare the training data\nprint(testLpRDD.take(1)) # should look similar to the previous cell\n\ntrain_test_100_LpRDD = loadAndPreprocess('lemm',100) # let's re-run with another vector size\n(trainLpRDD,testLpRDD) = train_test_100_LpRDD\nprint(testLpRDD.take(1))\nprint(trainLpRDD.take(1))", 
            "cell_type": "code", 
            "execution_count": 32, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "[LabeledPoint(0.0, [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.012736603569842138,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.022145734121861216,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.015008921926629391,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.013356428624859975,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.014571310671296732,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.031132612242499597,0.0,0.0,0.0,0.0,0.033358503557829565,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0315609538306996,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.014571310671296732,0.0,0.0,0.0,0.01741438691852247,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08720314787665039,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01374628930183428,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02439393551208377,0.0,0.0,0.0,0.0,0.0,0.0038580829233091393,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02439393551208377,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.011380695142373252,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.018705607496972403,0.0,0.0,0.011170492581712864,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.10684839755822446,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.030612388505521945,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06364892871524264,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04164708919840836,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.034216560352870816,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05342419877911223,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04429146824372243,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03856314108803714,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.017703009360026303,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0272422700255919,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.10327625097568062,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.21702627055672585,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04599366993357469,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.039994595896638944,0.0,0.0,0.0,0.0,0.0,0.04599366993357469,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.035149321193200696,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.025523398882538156,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.033358503557829565,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05342419877911223,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04599366993357469,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.022133834042433853,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.039994595896638944,0.0,0.0,0.0,0.01520352895284355,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02273517924327553,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02475735970928116,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.049077618043945906,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01610534987150498,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.035149321193200696,0.0,0.0,0.0,0.0,0.0,0.0,0.05973995923540897,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.019978232678534623,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04599366993357469,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.011275078651434855,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.049077618043945906,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09198733986714938,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.015621659386601183,0.0,0.0,0.0,0.04599366993357469,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.008034631599350478,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02370208339696205,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04371970171343418,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.009181371342789327,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.030017843853258782,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.026208363991549154,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.017703009360026303,0.0,0.0,0.0,0.0,0.0,0.017896167506876115,0.0,0.02592797471229202,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.039994595896638944,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.009376409238493096,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05543758469532631,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06364892871524264,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.013484813238587178,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.049077618043945906,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01169168394381097,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.032564067051101396,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.036171045092787645,0.0,0.0,0.004000430194681049,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.010762062720956983,0.0,0.0,0.0,0.0,0.007479927472350638,0.0,0.003641630093166419,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.10684839755822446,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.017143578758365665,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04599366993357469,0.0,0.0,0.026786031507333264,0.0,0.018201696571689543,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.12494126759522507,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.023372211612496824,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.049077618043945906,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04108992205795503,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0272422700255919,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.045482884420628714,0.0162715545514245,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.021045282912867603,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.018440254320920745,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.018260168538324587,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.014014302939375561,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.011170492581712864,0.0,0.0,0.0,0.0,0.1308047218149756,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02185985085671709,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.030482717077676278,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03730050846324203,0.0,0.0,0.0,0.0,0.0,0.08720314787665039,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2944657082636754,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.049077618043945906,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01322956339135169,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1999729794831947,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04599366993357469,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.034216560352870816,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.030930320889776052,0.0,0.0,0.020229411279986977,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.012857734656588059,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.035441654618233905,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.035149321193200696,0.0,0.0,0.0,0.01531091336477681,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01751327012155076,0.0,0.032564067051101396,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07998919179327789,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.020288263502125606,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.027718792347663154,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.008430247974243797,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.012037226015930049,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.018092870037000608,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.011376387679629046,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.049077618043945906,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.036171045092787645,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02370208339696205,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02821748631593507,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.010762062720956983,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01849744586675447,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.039994595896638944,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.016440376735231195,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03428715751673133,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04360157393832519,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.018293249462073394,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.039994595896638944,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.028740516247250103,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.016382261082127272,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.011851799558644857,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.21369679511644893,0.0,0.0,0.0,0.05342419877911223,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01531091336477681,0.0,0.0,0.0,0.03182446435762132,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04599366993357469,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0094759142649366,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08720314787665039,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03182446435762132,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.014014302939375561,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.009355683917044659,0.049077618043945906,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03465366172748723,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0474041667939241,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.025523398882538156,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01036862454115734,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.006483750455305096,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09815523608789181,0.0,0.0,0.0,0.0,0.0,0.026348420252000605,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01849744586675447,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01958119493715782,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03783578281292612,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.011275078651434855,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.025523398882538156,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01428918946518986,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.014014302939375561,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.049077618043945906,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.013356428624859975,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04599366993357469,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.002878481967414788,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.007357354587924229,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.022439450772166938,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01913446416862811,0.0,0.034699284103869736,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.004218851717997237,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01428918946518986,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.008006734669291847,0.0,0.0,0.0,0.0,0.0,0.02475735970928116,0.0,0.0,0.0,0.04157391494079504,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.032543109102849,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.026786031507333264,0.0,0.025473207139684276,0.0,0.0,0.0,0.0,0.0,0.08720314787665039,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.022439450772166938,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.044878901544333875,0.0,0.0,0.09198733986714938,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01891789140646306,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.005978302486740489,0.0,0.0,0.0,0.0,0.0,0.017703009360026303,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.034216560352870816,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04599366993357469,0.0,0.015941682766959276,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0272422700255919,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.017326830863743616,0.0,0.0,0.0,0.0,0.029290379702254638,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.006054284393049631,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03392681333309245,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01531091336477681,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.012980250128577286,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.034216560352870816,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.049077618043945906,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.036171045092787645,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02886775604899632,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04164708919840836,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.014861057691075093,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01036862454115734,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03062182672955362,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.013356428624859975,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2759620196014481,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02592797471229202,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09815523608789181,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03645199827486082,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.004218851717997237,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5376596331186808,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.049077618043945906,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.014715205276323667,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.016786212762582204,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09815523608789181,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03182446435762132,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.029290379702254638,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.010465638661338567,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.012857734656588059,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.035149321193200696,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05185594942458404,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08720314787665039,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.016786212762582204,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.006382138297581062,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.018092870037000608,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.021309987401712555,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04360157393832519,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09815523608789181,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.014677741306609884,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.035149321193200696,0.0,0.0,0.0,0.0029779656933370986,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.017703009360026303,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05342419877911223,0.0,0.0,0.0,0.0,0.03182446435762132,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04951471941856232,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04164708919840836,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04371393201389019,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02553346176426519,0.0,0.010272480514488758,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04599366993357469,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.030930320889776052,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01891789140646306,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.10684839755822446,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.032564067051101396,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.011066917021216927,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.017143578758365665,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.021045282912867603,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.017703009360026303,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.004383356027207089,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1999729794831947,0.0,0.0])]\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "[LabeledPoint(0.0, [0.01730655982377985,0.045028204382840185,0.07637472435997773,0.042890046052874164,0.07302782181622049,0.1384524785902388,0.2074681106135228,0.09074474397362073,0.09984843251900194,0.1597574920304031,0.056829972009760706,0.17574880095731008,0.1736507408364363,0.0,0.08419904896411998,0.03185335921294318,0.02714910064882251,0.02239724489096134,0.02886131863018766,0.06502315505843996,0.2375234915140254,0.04312192975940643,0.0,0.13404945757161074,0.0,0.083152320643562,0.09855693351863973,0.023617160959519868,0.06588533144332052,0.14186982096498008,0.13858720107260336,0.07675484158875623,0.08172924859742939,0.12940815304264155,0.1609541271472273,0.0,0.12005972919333587,0.11659715351764918,0.04209952448205999,0.0692262392951194,0.054655819097232855,0.0692262392951194,0.029389498005929306,0.08807842815688952,0.1486029062380973,0.14718449105986933,0.045372371986810364,0.03647997801367858,0.1437401368593856,0.03353587799378589,0.17972717853420347,0.10419044450186177,0.0732586401788783,0.0,0.04403921407844476,0.06672450566213799,0.03945444712862801,0.10633253646144164,0.052658910977732364,0.05471996702051788,0.03353587799378589,0.2649320839077648,0.030014932298333966,0.03059544191295774,0.03042620127952798,0.03012388993095001,0.07798991240684827,0.07923063574265152,0.03059544191295774,0.05058340628748957,0.09300470980716401,0.07469782976300601,0.06826339560152181,0.06906984208709786,0.08831069463592159,0.0718700684296928,0.08127894382304995,0.03042620127952798,0.25579062249176193,0.0718700684296928,0.10655802207836844,0.07675484158875623,0.053505047419009695,0.0,0.04647216082038822,0.10060763398135769,0.07606550319881994,0.18270758749411564,0.04339832027060962,0.028340593151423836,0.14583713402830495,0.056576345591944924,0.049798553175337344,0.20202094126538142,0.0,0.1419828103467727,0.12005972919333587,0.05316626823072082,0.08917507903168281,0.14605564363244097])]\n[LabeledPoint(0.0, [0.0,0.09555648709306393,0.06650730499987755,0.03896868731712061,0.0,0.06485262305142178,0.0,0.14483429705512985,0.09082072966939189,0.07549998570409615,0.560244059521575,0.035220467486156315,0.2047633375545263,0.18364931090753867,0.0,0.037420010684205196,0.0,0.06896787446799157,0.05196697012257093,0.03353796057247997,0.06544290254870208,0.05070534178164689,0.04511097412899775,0.08986993914245968,0.0,0.12130801496899131,0.04673422962497877,0.019221499447753542,0.0,0.03861140424657963,0.0,0.37688330299323064,0.15089821079560997,0.07664484338910228,0.14915434094749086,0.08285463796809178,0.026034750377138018,0.025727537258835444,0.06683737388729409,0.0,0.0,0.07413001654707625,0.11802102465724888,0.040362386602060214,0.04196126612660248,0.032541517317035626,0.02974081046341126,0.03637134521878882,0.0,0.03419233320319944,0.2886469727235599,0.09713360806161395,0.046212510946241306,0.12603762945865105,0.0,0.029450995493240983,0.19093007289136307,0.02995358915626047,0.0,0.05423441477772978,0.0,0.0,0.08970106083889617,0.042203282997170015,0.0,0.053064297874254825,0.046048078367534905,0.0,0.0,0.01856674285955115,0.035201154959805595,0.09082072966939189,0.03525158254526522,0.03256771615724711,0.06012028430139099,0.032323377267404536,0.0,0.02544287203004521,0.0882768212391201,0.03872722272063411,0.05883922943886619,0.043833660737003566,0.03134737588840616,0.0,0.0,0.10811715458266122,0.01952557901944105,0.039191792127399865,0.0,0.023649271465363116,0.09956508207512928,0.04673422962497877,0.03575712690279907,0.07980103448367866,0.0,0.09261101398991775,0.0,0.17235018810003425,0.04441788401931067,0.050028439931542046])]\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "## Task 6) Train some classifiers \n\nUse the `LabeledPoint` objects to train a classifier, specifically the *LogisticRegression*, *Naive Bayes*, and *Support Vector Machine*. Calculate the accuracy of the model on the training set (again, follow this example [http://spark.apache.org/docs/2.1.0/ml-classification-regression.html#logistic-regression](http://spark.apache.org/docs/2.0.0/ml-classification-regression.html#logistic-regression) and here is the documentation for the classifiers [LogisticRegressionWithLBFGS](http://spark.apache.org/docs/2.1.0/api/python/pyspark.mllib.html#pyspark.mllib.classification.LogisticRegressionWithLBFGS), [NaiveBayes](http://spark.apache.org/docs/2.1.0/api/python/pyspark.mllib.html#pyspark.mllib.classification.NaiveBayes), [SVMWithSGD](http://spark.apache.org/docs/2.1.0/api/python/pyspark.mllib.html#pyspark.mllib.classification.SVMWithSGD).  (10%) ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "from pyspark.mllib.classification import (NaiveBayes, LogisticRegressionWithLBFGS, SVMWithSGD) \nimport numpy\n\n# train the model with an (f,[(w,c), ...]) RDD. This is practical as we can reuse the function for TF.IDF\ndef trainModel(lpRDD):\n    \"\"\" Train 3 classifier models on the given RDD with LabeledPoint objects. A list of trained model is returned. \"\"\"\n    lpRDD.persist(StorageLevel.MEMORY_ONLY) # not really needed as the Spark implementations ensure caching themselves. \n                    # Other implementations might not, however. \n    # Train a classifier model.\n    print('Starting to train the models') # give some immediate feedback\n    model1 = LogisticRegressionWithLBFGS.train(lpRDD) # this is the best model\n    print('Trained LR (model1)')\n    #print('type(model1)')\n    model2 = NaiveBayes.train(lpRDD) # doesn't work well. \n    print('Trained NB (model2)')\n    #print(type(model2))\n    model3 = SVMWithSGD.train(lpRDD) # or this ... doesn't do well either.\n    print('Trained SVM (model3)')\n    return [model1,model2,model3]\n\ndef testModel(model, lpRDD):\n    \"\"\" Tests the classificatio accuracy of the given model on the given RDD with LabeledPoint objects. \"\"\"\n    lpRDD.persist(StorageLevel.MEMORY_ONLY)\n    # Make prediction and evaluate training set accuracy.\n    # Get the prediction and the ground truth label\n    predictionAndLabel = lpRDD.map(lambda p: (model.predict(p.features), p.label)) # get the prediction and ground truth (label) for each item.\n    correct = predictionAndLabel.filter(lambda xv: xv[0] == xv[1]).count() # count the correct predictions \n    accuracy = 1.0 * correct / lpRDD.count() # and calculate the accuracy \n    print('Accuracy {:.2%} (data items: {}, correct: {})'.format(accuracy,lpRDD.count(), correct)) # report to console\n    return accuracy # and return the value  \n\nmodels = trainModel(trainLpRDD) # just for testing\ntestModel(models[2], trainLpRDD) # just for testing", 
            "cell_type": "code", 
            "execution_count": 36, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Starting to train the models\nTrained LR (model1)\nTrained NB (model2)\nTrained SVM (model3)\nAccuracy 83.40% (data items: 2602, correct: 2170)\n"
                }, 
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "0.8339738662567256"
                    }, 
                    "execution_count": 36, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "### Task 7) Automate training and testing\n\nWe automate now the whole process from reading the files, through preprocessing, and training up to evaluating the models. In the end we have a single function that takes all the parameters we are interested in and produces trained models and an evaluation. (5%) ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# this function combines tasks f) and g)\n# this method should take RDDs with (f,[(w,c), ...])\ndef trainTestModel(trainRDD,testRDD):\n    \"\"\" Trains 3 models and tests them on training and test data. Returns a matrix the training and testing (rows) accuracy values for all models (columns). \"\"\"\n    models = trainModel(trainRDD)\n    results = [[],[]] # matrix for 2 modes (training/test) vs n models (currently 3)\n    for mdl in models:\n        print('Training')\n        results[0].append(testModel(mdl, trainRDD))\n        print('Testing')\n        results[1].append(testModel(mdl, testRDD))\n    return results\n\ndef trainTestFolder(folder,N):\n    \"\"\" Reads data from a folder, preproceses the data, and trains and evaluates models on it. \"\"\"\n    print('Start loading and preprocessing') \n    train_test_LpRDD = loadAndPreprocess(folder,N) # create the RDDs\n    print('Finished loading and preprocessing')\n    (trainLpRDD,testLpRDD) = train_test_LpRDD # unpack the RDDs \n    return trainTestModel(trainLpRDD,testLpRDD) # train and test\n\ntrainTestFolder('lemm',1000) ", 
            "cell_type": "code", 
            "execution_count": 37, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Start loading and preprocessing\nFinished loading and preprocessing\nStarting to train the models\nTrained LR (model1)\nTrained NB (model2)\nTrained SVM (model3)\nTraining\nAccuracy 100.00% (data items: 2602, correct: 2602)\nTesting\nAccuracy 97.59% (data items: 291, correct: 284)\nTraining\nAccuracy 94.31% (data items: 2602, correct: 2454)\nTesting\nAccuracy 92.10% (data items: 291, correct: 268)\nTraining\nAccuracy 83.40% (data items: 2602, correct: 2170)\nTesting\nAccuracy 83.16% (data items: 291, correct: 242)\n"
                }, 
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "[[1.0, 0.9431206764027671, 0.8339738662567256],\n [0.9759450171821306, 0.9209621993127147, 0.8316151202749141]]"
                    }, 
                    "execution_count": 37, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "## Task 8) Run experiments \n\nWe have now a single function that allows us to vary the vector size easily. Test vector sizes 3, 30, 300, 3000, 30000 and examine the effect on the classification accuracy in Experiment 1.\n\nUse the function from Task 7) to test different data types. The dataset has raw text in folder `bare`, lemmatised text in  `lemm` (similar to stemming, reduces to basic word forms), `stop` (with stopwords removed), and `lemm_stop` (lemmatised and stopwords removed). Test how the classification accuracy differs for these four data types in Experiment 2. \n\nComment on the results in a few sentences, considering the differences in performance between the different conditions as well as train and test values. 15%", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "folder = 'bare'\nN = numpy.array([3,30,300,3000,30000]) \nprint('\\nEXPERIMENT 1: Testing different vector sizes')\nresults1 = []\nfor n in N:\n    print('N = {}'.format(n))\n    result = {'n':n, 't':folder}\n    result['acc'] = trainTestFolder(folder,n)\n    results1.append(result)\n    \nn = 3000\nprint('EXPERIMENT 2: Testing different data types')\nresults2 = []\ntypeFolders = ['bare','stop','lemm','lemm_stop']\nfor folder in typeFolders:\n    print('Path = {}'.format(folder))\n    result = {'n':n, 't':folder}\n    result['acc'] = trainTestFolder(folder,n)\n    results2.append(result)\n\n# This wasn't asked for, but can be useful if you want to analyse the results later: \nimport pickle as pkl\nwith open('results1.pkl','wb') as f:\n    pkl.dump(results1,f)\nwith open('results2.pkl','wb') as f:\n    pkl.dump(results2,f)", 
            "cell_type": "code", 
            "execution_count": 39, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "\nEXPERIMENT 1: Testing different vector sizes\nN = 3\nStart loading and preprocessing\nFinished loading and preprocessing\nStarting to train the models\nTrained LR (model1)\nTrained NB (model2)\nTrained SVM (model3)\nTraining\nAccuracy 83.40% (data items: 2602, correct: 2170)\nTesting\nAccuracy 83.16% (data items: 291, correct: 242)\nTraining\nAccuracy 83.40% (data items: 2602, correct: 2170)\nTesting\nAccuracy 83.16% (data items: 291, correct: 242)\nTraining\nAccuracy 83.40% (data items: 2602, correct: 2170)\nTesting\nAccuracy 83.16% (data items: 291, correct: 242)\nN = 30\nStart loading and preprocessing\nFinished loading and preprocessing\nStarting to train the models\nTrained LR (model1)\nTrained NB (model2)\nTrained SVM (model3)\nTraining\nAccuracy 85.47% (data items: 2602, correct: 2224)\nTesting\nAccuracy 86.60% (data items: 291, correct: 252)\nTraining\nAccuracy 83.40% (data items: 2602, correct: 2170)\nTesting\nAccuracy 83.16% (data items: 291, correct: 242)\nTraining\nAccuracy 83.40% (data items: 2602, correct: 2170)\nTesting\nAccuracy 83.16% (data items: 291, correct: 242)\nN = 300\nStart loading and preprocessing\nFinished loading and preprocessing\nStarting to train the models\nTrained LR (model1)\nTrained NB (model2)\nTrained SVM (model3)\nTraining\nAccuracy 100.00% (data items: 2602, correct: 2602)\nTesting\nAccuracy 96.91% (data items: 291, correct: 282)\nTraining\nAccuracy 86.24% (data items: 2602, correct: 2244)\nTesting\nAccuracy 83.51% (data items: 291, correct: 243)\nTraining\nAccuracy 83.40% (data items: 2602, correct: 2170)\nTesting\nAccuracy 83.16% (data items: 291, correct: 242)\nN = 3000\nStart loading and preprocessing\nFinished loading and preprocessing\nStarting to train the models\nTrained LR (model1)\nTrained NB (model2)\nTrained SVM (model3)\nTraining\nAccuracy 100.00% (data items: 2602, correct: 2602)\nTesting\nAccuracy 97.59% (data items: 291, correct: 284)\nTraining\nAccuracy 97.50% (data items: 2602, correct: 2537)\nTesting\nAccuracy 95.88% (data items: 291, correct: 279)\nTraining\nAccuracy 83.40% (data items: 2602, correct: 2170)\nTesting\nAccuracy 83.16% (data items: 291, correct: 242)\nN = 30000\nStart loading and preprocessing\nFinished loading and preprocessing\nStarting to train the models\nTrained LR (model1)\nTrained NB (model2)\nTrained SVM (model3)\nTraining\nAccuracy 100.00% (data items: 2602, correct: 2602)\nTesting\nAccuracy 98.28% (data items: 291, correct: 286)\nTraining\nAccuracy 86.09% (data items: 2602, correct: 2240)\nTesting\nAccuracy 84.54% (data items: 291, correct: 246)\nTraining\nAccuracy 83.44% (data items: 2602, correct: 2171)\nTesting\nAccuracy 83.16% (data items: 291, correct: 242)\nEXPERIMENT 2: Testing different data types\nPath = bare\nStart loading and preprocessing\nFinished loading and preprocessing\nStarting to train the models\nTrained LR (model1)\nTrained NB (model2)\nTrained SVM (model3)\nTraining\nAccuracy 100.00% (data items: 2602, correct: 2602)\nTesting\nAccuracy 97.59% (data items: 291, correct: 284)\nTraining\nAccuracy 97.50% (data items: 2602, correct: 2537)\nTesting\nAccuracy 95.88% (data items: 291, correct: 279)\nTraining\nAccuracy 83.40% (data items: 2602, correct: 2170)\nTesting\nAccuracy 83.16% (data items: 291, correct: 242)\nPath = stop\nStart loading and preprocessing\nFinished loading and preprocessing\nStarting to train the models\nTrained LR (model1)\nTrained NB (model2)\nTrained SVM (model3)\nTraining\nAccuracy 100.00% (data items: 2602, correct: 2602)\nTesting\nAccuracy 97.59% (data items: 291, correct: 284)\nTraining\nAccuracy 96.89% (data items: 2602, correct: 2521)\nTesting\nAccuracy 93.81% (data items: 291, correct: 273)\nTraining\nAccuracy 83.40% (data items: 2602, correct: 2170)\nTesting\nAccuracy 83.16% (data items: 291, correct: 242)\nPath = lemm\nStart loading and preprocessing\nFinished loading and preprocessing\nStarting to train the models\nTrained LR (model1)\nTrained NB (model2)\nTrained SVM (model3)\nTraining\nAccuracy 100.00% (data items: 2602, correct: 2602)\nTesting\nAccuracy 97.59% (data items: 291, correct: 284)\nTraining\nAccuracy 97.43% (data items: 2602, correct: 2535)\nTesting\nAccuracy 94.85% (data items: 291, correct: 276)\nTraining\nAccuracy 83.40% (data items: 2602, correct: 2170)\nTesting\nAccuracy 83.16% (data items: 291, correct: 242)\nPath = lemm_stop\nStart loading and preprocessing\nFinished loading and preprocessing\nStarting to train the models\nTrained LR (model1)\nTrained NB (model2)\nTrained SVM (model3)\nTraining\nAccuracy 100.00% (data items: 2602, correct: 2602)\nTesting\nAccuracy 97.94% (data items: 291, correct: 285)\nTraining\nAccuracy 96.93% (data items: 2602, correct: 2522)\nTesting\nAccuracy 92.44% (data items: 291, correct: 269)\nTraining\nAccuracy 83.40% (data items: 2602, correct: 2170)\nTesting\nAccuracy 83.16% (data items: 291, correct: 242)\n"
                }
            ], 
            "metadata": {
                "scrolled": false
            }
        }, 
        {
            "source": "## Comment\nThe test and training accuracy increase with the vector size. This is because we loose information in the hashing process, and in addition by the IDF calculation on small vectors. For vecture sizes of 3000 and higher, Logistic Regression produces perfect classification on the Training set, and reaches over 98% for 30000 vector dimensions. \n\nFor the different preprocessing types (bare, stop, lemm, lemm_stop) it is not clear a priori, which of them might be more effective, as spam can be expected to be different in terms of topics and style, which meanse that may contain relevant information. In practice the preprocessing has less impact on model performance than the vector size, the accuracy is similar in all 4 conditions. Specifically for the best model, Logistic Regression, the test accuracy is 97.59% in all cases but lemm_stop, where it is 97.94. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# This wasn't asked for but it is a nice way to show the results graphically.\nfrom pyspark.sql import DataFrame\nimport pandas as pd\nimport pixiedust\n\nimport pickle as pkl\nwith open('results1.pkl','rb') as f:\n    results1 = pkl.load(f)\n\nwith open('results2.pkl','rb') as f:\n    results2 = pkl.load(f)\n\n\n#We'll create a structured data frame of our results, for that we'll provide all \nmodels = ['LR','NB','SVM']\nmodes = ['Train','Test']\n\ndef makePandasDf():\n    df = pd.DataFrame(columns=['t','model','n','mode','acc'])\n    for r in results1:\n        for tst in (0,1): \n            for mod in (0,1,2):\n                r2 = r.copy() \n                r2['model']=models[mod]\n                r2['mode']=modes[tst]\n                r2['acc']=r['acc'][tst][mod]\n                #print(r2)\n                df = df.append(r2, ignore_index=True)\n\n    df2 = pd.DataFrame(columns=['t','model','n','mode','acc'])\n    for r in results2:\n        for tst in (0,1): \n            for mod in (0,1,2):\n                r2 = r.copy() \n                r2['model']=models[mod]\n                r2['mode']=modes[tst]\n                r2['acc']=r['acc'][tst][mod]\n                #print(r2)\n                df2 = df.append(r2, ignore_index=True)\n\n    return df,df2\n        \n#sdf = makePandasDf(res3a)\ndisplay(makePandasDf()[0])", 
            "cell_type": "code", 
            "execution_count": 8, 
            "outputs": [
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/html": "<style type=\"text/css\">.pd_warning{display:none;}</style><div class=\"pd_warning\"><em>Hey, there's something awesome here! To see it, open this notebook outside GitHub, in a viewer like Jupyter</em></div><script class=\"pd_save is-viewer-good\">\n                    function setChartScript() {\n                        if (!window.Bokeh) {\n                            setTimeout(setChartScript, 250)\n                        } else {\n                            var d = document.getElementById(\"pd-bkchartdiv-c7015f59\")\n                            if (d){\n                                var el = document.createElement('div')\n                                el.innerHTML = `\n<script type=\"text/javascript\">\n  (function() {\n    var fn = function() {\n      Bokeh.safely(function() {\n        (function(root) {\n          function embed_document(root) {\n            \n          var docs_json = '{\"dee38daa-80e3-47fa-a0f4-be58702c77f6\":{\"roots\":{\"references\":[{\"attributes\":{},\"id\":\"47b8d4bf-bc82-4129-96e7-a494bf2a6e54\",\"type\":\"LinearScale\"},{\"attributes\":{\"callback\":null,\"start\":0},\"id\":\"c5267628-aff1-4e54-8c9b-82ca018243c1\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"acda570e-172f-4bb4-89c4-f709eb084aa2\",\"type\":\"PanTool\"},{\"attributes\":{\"bottom\":{\"expr\":{\"id\":\"d1cc8f78-ff34-41fa-bd76-edf6fc76e590\",\"type\":\"Stack\"}},\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"top\":{\"expr\":{\"id\":\"44168190-6d9f-487b-91a4-5b93791c57e0\",\"type\":\"Stack\"}},\"width\":{\"value\":0.9},\"x\":{\"field\":\"pd_stacked_col\"}},\"id\":\"81ee1b00-7ecd-4603-a78e-96b47df66235\",\"type\":\"VBar\"},{\"attributes\":{\"data_source\":{\"id\":\"d2c05425-4f51-4c0c-b7c6-98fbaadce318\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"08a0f870-072c-4d46-85cc-ad8e116a3fba\",\"type\":\"VBar\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"81ee1b00-7ecd-4603-a78e-96b47df66235\",\"type\":\"VBar\"},\"selection_glyph\":null,\"view\":{\"id\":\"9937f78e-9625-4f7a-9f65-d5e57c8d801a\",\"type\":\"CDSView\"}},\"id\":\"ca2f1d40-0280-42cf-81d3-e9d17173fef9\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"da904b13-d4d7-4c42-8e98-9bada2d50cf9\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"7945d2f2-a0be-4da7-b49b-bafc15c75c5e\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"5f6e3092-1a80-4814-af09-2a2fd0720fb8\",\"type\":\"CategoricalTickFormatter\"},{\"attributes\":{},\"id\":\"5b69ed2f-c27f-48a5-94ac-e8934862ea5c\",\"type\":\"CategoricalTicker\"},{\"attributes\":{},\"id\":\"034a7fdd-5e4b-4930-bfda-298dbf269c46\",\"type\":\"BasicTicker\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"70c653cb-4705-4352-a46e-8a1151226d7b\",\"type\":\"PanTool\"},{\"id\":\"7945d2f2-a0be-4da7-b49b-bafc15c75c5e\",\"type\":\"WheelZoomTool\"},{\"id\":\"4eb5dd1f-e53b-4a97-9e83-39a03985d8a1\",\"type\":\"BoxZoomTool\"},{\"id\":\"2e0213fb-2682-417b-ae1c-bd7ae9e90373\",\"type\":\"SaveTool\"},{\"id\":\"01a6e3b9-ef0a-4a15-be39-7a350e50e69a\",\"type\":\"ResetTool\"},{\"id\":\"1e243dd6-9eaf-4f4e-9636-717da2fd2d7b\",\"type\":\"HelpTool\"}]},\"id\":\"892eaacf-47f7-4a8f-8b9c-43657b151363\",\"type\":\"Toolbar\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"369bd57b-930f-4449-baab-a997a2b18674\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"df1b6112-a725-4415-8f15-134d679a2c87\",\"type\":\"BasicTicker\"}},\"id\":\"2a5c1d7f-2676-460f-9f46-2c98c40f2cb7\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"0a35ad43-4a96-4103-bd7e-069bb7abc4c6\",\"type\":\"CategoricalTickFormatter\"},{\"attributes\":{\"bottom\":{\"expr\":{\"id\":\"079d22dc-71d4-487f-8ffa-399537fceef1\",\"type\":\"Stack\"}},\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"top\":{\"expr\":{\"id\":\"2d8e57dd-dd2f-4918-9e26-5524be0a9e5c\",\"type\":\"Stack\"}},\"width\":{\"value\":0.9},\"x\":{\"field\":\"pd_stacked_col\"}},\"id\":\"97f3bd81-4039-4bce-a6ae-66117129d25a\",\"type\":\"VBar\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"acda570e-172f-4bb4-89c4-f709eb084aa2\",\"type\":\"PanTool\"},{\"id\":\"cce9c993-8fd5-4bec-9799-363f0d74e7d3\",\"type\":\"WheelZoomTool\"},{\"id\":\"c7b041be-b319-4ecb-a849-2106473c51ee\",\"type\":\"BoxZoomTool\"},{\"id\":\"cff826f0-f551-4ef4-83a6-21a12271dd50\",\"type\":\"SaveTool\"},{\"id\":\"e2578b93-9c64-4d7b-9a08-5687fe8b5da4\",\"type\":\"ResetTool\"},{\"id\":\"676ac94f-5776-4fef-a10f-1a7e11c4d328\",\"type\":\"HelpTool\"}]},\"id\":\"c16e18a4-9f16-4fc9-a70c-3aadd06b6b57\",\"type\":\"Toolbar\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"pd_stacked_col\",\"acc\"],\"data\":{\"acc\":[0.8316151202749141,0.865979381443299,0.9690721649484536,0.9759450171821306,0.9828178694158075,0.8339738662567256,0.8547271329746349,1.0,1.0,1.0],\"pd_stacked_col\":[\"Test,bare,3\",\"Test,bare,30\",\"Test,bare,300\",\"Test,bare,3000\",\"Test,bare,30000\",\"Train,bare,3\",\"Train,bare,30\",\"Train,bare,300\",\"Train,bare,3000\",\"Train,bare,30000\"]}},\"id\":\"20a60111-d25a-4b60-83bf-64791b127ae8\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"label\":{\"value\":\"acc\"},\"renderers\":[{\"id\":\"ca2f1d40-0280-42cf-81d3-e9d17173fef9\",\"type\":\"GlyphRenderer\"}]},\"id\":\"a10edc1b-1ace-4909-8056-cad9a986a59b\",\"type\":\"LegendItem\"},{\"attributes\":{},\"id\":\"70cf5424-2aa0-4c97-a6c9-bf348d8f60f0\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"01a6e3b9-ef0a-4a15-be39-7a350e50e69a\",\"type\":\"ResetTool\"},{\"attributes\":{\"axis_label\":\"mode,t,n\",\"formatter\":{\"id\":\"cdb74704-27da-4617-ac11-3c7779a2e8a0\",\"type\":\"CategoricalTickFormatter\"},\"major_label_orientation\":1,\"minor_tick_line_color\":{\"value\":null},\"plot\":{\"id\":\"c81ea69e-7107-4105-811f-df5a180a8923\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1211eddf-f659-43d0-b79f-134ff3425b91\",\"type\":\"CategoricalTicker\"}},\"id\":\"07489ba8-6994-467a-a4cc-1888870accb0\",\"type\":\"CategoricalAxis\"},{\"attributes\":{},\"id\":\"eaeddb2e-f844-4268-9bfa-6cc9f1ff8e38\",\"type\":\"CategoricalScale\"},{\"attributes\":{\"label\":{\"value\":\"acc\"},\"renderers\":[{\"id\":\"a5071050-e9f6-42fc-8d95-3b234e690686\",\"type\":\"GlyphRenderer\"}]},\"id\":\"24aca68b-a554-407d-b64d-a0cb124d5d39\",\"type\":\"LegendItem\"},{\"attributes\":{\"children\":[{\"id\":\"61f71f3a-73d7-4147-a44e-9004759c81ca\",\"type\":\"ToolbarBox\"},{\"id\":\"bd6c89a8-635c-445d-9359-400bb561f971\",\"type\":\"Column\"}]},\"id\":\"ef9de844-3f6f-4cdf-a7bb-a03e3724c7f4\",\"type\":\"Column\"},{\"attributes\":{\"bottom\":{\"expr\":{\"id\":\"fb31333d-0e1b-41f4-862c-825a1c8b2475\",\"type\":\"Stack\"}},\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"top\":{\"expr\":{\"id\":\"d7667075-72d8-4c2a-94e3-bd74fba001f3\",\"type\":\"Stack\"}},\"width\":{\"value\":0.9},\"x\":{\"field\":\"pd_stacked_col\"}},\"id\":\"b08626ae-86a0-4f49-a37f-3c95abbf601f\",\"type\":\"VBar\"},{\"attributes\":{\"plot\":null,\"text\":\"model = SVM\"},\"id\":\"d9df53c0-5710-4be2-861a-de4d86710f75\",\"type\":\"Title\"},{\"attributes\":{\"children\":[{\"id\":\"ce111a15-3b86-4dc6-bda0-25b086950898\",\"subtype\":\"Figure\",\"type\":\"Plot\"}]},\"id\":\"c981e638-10e0-47b5-852c-bd3266a13695\",\"type\":\"Row\"},{\"attributes\":{\"axis_label\":\"acc\",\"formatter\":{\"id\":\"5a76ac5e-ceee-45d8-b66e-5f4929650376\",\"type\":\"BasicTickFormatter\"},\"minor_tick_line_color\":{\"value\":null},\"plot\":{\"id\":\"ce111a15-3b86-4dc6-bda0-25b086950898\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"034a7fdd-5e4b-4930-bfda-298dbf269c46\",\"type\":\"BasicTicker\"}},\"id\":\"64b5b67b-953b-498f-be30-0709d8fe4245\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"05fb7596-507f-4d8f-9784-f490db1dd9a8\",\"type\":\"HelpTool\"},{\"attributes\":{\"axis_label\":\"acc\",\"formatter\":{\"id\":\"02b0077c-6d5b-4129-97f3-895112d699b1\",\"type\":\"BasicTickFormatter\"},\"minor_tick_line_color\":{\"value\":null},\"plot\":{\"id\":\"369bd57b-930f-4449-baab-a997a2b18674\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"df1b6112-a725-4415-8f15-134d679a2c87\",\"type\":\"BasicTicker\"}},\"id\":\"dba0f553-7e09-4e7e-8b2c-40c0c907892f\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"df1b6112-a725-4415-8f15-134d679a2c87\",\"type\":\"BasicTicker\"},{\"attributes\":{\"fields\":[\"acc\"]},\"id\":\"44168190-6d9f-487b-91a4-5b93791c57e0\",\"type\":\"Stack\"},{\"attributes\":{\"data_source\":{\"id\":\"cb3831ab-198a-4ce9-8bc6-607e6ee0b6f1\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"9ab1a8a1-02d5-414c-8674-e109c4e2a234\",\"type\":\"VBar\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"97f3bd81-4039-4bce-a6ae-66117129d25a\",\"type\":\"VBar\"},\"selection_glyph\":null,\"view\":{\"id\":\"5ce9090c-8f98-43a5-8d57-cf1b6db8a014\",\"type\":\"CDSView\"}},\"id\":\"34b735a5-e0b4-41b6-be99-2a65aa6de6d9\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"fields\":[]},\"id\":\"d1cc8f78-ff34-41fa-bd76-edf6fc76e590\",\"type\":\"Stack\"},{\"attributes\":{},\"id\":\"464e6f71-ad8b-4912-82b3-0533531c55f2\",\"type\":\"ResetTool\"},{\"attributes\":{\"bottom\":{\"expr\":{\"id\":\"079d22dc-71d4-487f-8ffa-399537fceef1\",\"type\":\"Stack\"}},\"fill_color\":{\"value\":\"#ff7f0e\"},\"line_color\":{\"value\":\"#ff7f0e\"},\"top\":{\"expr\":{\"id\":\"2d8e57dd-dd2f-4918-9e26-5524be0a9e5c\",\"type\":\"Stack\"}},\"width\":{\"value\":0.9},\"x\":{\"field\":\"pd_stacked_col\"}},\"id\":\"9ab1a8a1-02d5-414c-8674-e109c4e2a234\",\"type\":\"VBar\"},{\"attributes\":{},\"id\":\"5a76ac5e-ceee-45d8-b66e-5f4929650376\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"fields\":[\"acc\"]},\"id\":\"d7667075-72d8-4c2a-94e3-bd74fba001f3\",\"type\":\"Stack\"},{\"attributes\":{\"source\":{\"id\":\"d2c05425-4f51-4c0c-b7c6-98fbaadce318\",\"type\":\"ColumnDataSource\"}},\"id\":\"9937f78e-9625-4f7a-9f65-d5e57c8d801a\",\"type\":\"CDSView\"},{\"attributes\":{\"overlay\":{\"id\":\"280ee3c7-a2e7-4ab5-8b4b-5458a9f90337\",\"type\":\"BoxAnnotation\"}},\"id\":\"c7b041be-b319-4ecb-a849-2106473c51ee\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"16a4fcda-c37e-4556-924f-05a140dfc2ab\",\"type\":\"SaveTool\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"pd_stacked_col\",\"acc\"],\"data\":{\"acc\":[0.8316151202749141,0.8316151202749141,0.8350515463917526,0.9587628865979382,0.845360824742268,0.8339738662567256,0.8339738662567256,0.862413528055342,0.9750192159877018,0.8608762490392006],\"pd_stacked_col\":[\"Test,bare,3\",\"Test,bare,30\",\"Test,bare,300\",\"Test,bare,3000\",\"Test,bare,30000\",\"Train,bare,3\",\"Train,bare,30\",\"Train,bare,300\",\"Train,bare,3000\",\"Train,bare,30000\"]}},\"id\":\"cb3831ab-198a-4ce9-8bc6-607e6ee0b6f1\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"fields\":[]},\"id\":\"079d22dc-71d4-487f-8ffa-399537fceef1\",\"type\":\"Stack\"},{\"attributes\":{\"grid_line_color\":{\"value\":null},\"plot\":{\"id\":\"369bd57b-930f-4449-baab-a997a2b18674\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"5b69ed2f-c27f-48a5-94ac-e8934862ea5c\",\"type\":\"CategoricalTicker\"}},\"id\":\"969eac38-e1fb-4897-94ea-5e2d72a81fde\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"f4d82e7a-ea22-4e06-a228-3e6d4443f9f1\",\"type\":\"CategoricalScale\"},{\"attributes\":{},\"id\":\"e2578b93-9c64-4d7b-9a08-5687fe8b5da4\",\"type\":\"ResetTool\"},{\"attributes\":{\"fields\":[\"acc\"]},\"id\":\"2d8e57dd-dd2f-4918-9e26-5524be0a9e5c\",\"type\":\"Stack\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"15aee8ae-d391-4403-ad0c-4e9d9ac39842\",\"type\":\"PanTool\"},{\"id\":\"64511e6a-87d5-4079-be4b-a618555c84a0\",\"type\":\"WheelZoomTool\"},{\"id\":\"55de4492-34b3-4018-bac8-6a29ea1f5830\",\"type\":\"BoxZoomTool\"},{\"id\":\"16a4fcda-c37e-4556-924f-05a140dfc2ab\",\"type\":\"SaveTool\"},{\"id\":\"464e6f71-ad8b-4912-82b3-0533531c55f2\",\"type\":\"ResetTool\"},{\"id\":\"05fb7596-507f-4d8f-9784-f490db1dd9a8\",\"type\":\"HelpTool\"}]},\"id\":\"a06dcb43-e848-46bc-ba96-261c5db46d4b\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"2e0213fb-2682-417b-ae1c-bd7ae9e90373\",\"type\":\"SaveTool\"},{\"attributes\":{\"fields\":[]},\"id\":\"fb31333d-0e1b-41f4-862c-825a1c8b2475\",\"type\":\"Stack\"},{\"attributes\":{\"toolbar\":{\"id\":\"3cd83663-f0db-43a6-8fa4-7f35d9de8ca0\",\"type\":\"ProxyToolbar\"},\"toolbar_location\":\"above\"},\"id\":\"61f71f3a-73d7-4147-a44e-9004759c81ca\",\"type\":\"ToolbarBox\"},{\"attributes\":{\"axis_label\":\"acc\",\"formatter\":{\"id\":\"6a096a01-4943-4d53-a119-2b1cb3babcab\",\"type\":\"BasicTickFormatter\"},\"minor_tick_line_color\":{\"value\":null},\"plot\":{\"id\":\"c81ea69e-7107-4105-811f-df5a180a8923\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"70cf5424-2aa0-4c97-a6c9-bf348d8f60f0\",\"type\":\"BasicTicker\"}},\"id\":\"961bbe31-bcb8-45f1-9cab-300d39271f85\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"cce9c993-8fd5-4bec-9799-363f0d74e7d3\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"source\":{\"id\":\"20a60111-d25a-4b60-83bf-64791b127ae8\",\"type\":\"ColumnDataSource\"}},\"id\":\"817399fd-58e0-4daa-8b9d-8a3773c0284f\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"9e3c731b-94fb-4ced-9195-d35e111d106a\",\"type\":\"CategoricalTicker\"},{\"attributes\":{\"axis_label\":\"mode,t,n\",\"formatter\":{\"id\":\"0a35ad43-4a96-4103-bd7e-069bb7abc4c6\",\"type\":\"CategoricalTickFormatter\"},\"major_label_orientation\":1,\"minor_tick_line_color\":{\"value\":null},\"plot\":{\"id\":\"369bd57b-930f-4449-baab-a997a2b18674\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"5b69ed2f-c27f-48a5-94ac-e8934862ea5c\",\"type\":\"CategoricalTicker\"}},\"id\":\"a84abc2a-e296-44fe-902a-6c10aaf79164\",\"type\":\"CategoricalAxis\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"c81ea69e-7107-4105-811f-df5a180a8923\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"70cf5424-2aa0-4c97-a6c9-bf348d8f60f0\",\"type\":\"BasicTicker\"}},\"id\":\"50dc2479-aca3-45e0-9a9d-3f7f4ecc9bb9\",\"type\":\"Grid\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"pd_stacked_col\",\"acc\"],\"data\":{\"acc\":[0.8316151202749141,0.8316151202749141,0.8316151202749141,0.8316151202749141,0.8316151202749141,0.8339738662567256,0.8339738662567256,0.8339738662567256,0.8339738662567256,0.834358186010761],\"pd_stacked_col\":[\"Test,bare,3\",\"Test,bare,30\",\"Test,bare,300\",\"Test,bare,3000\",\"Test,bare,30000\",\"Train,bare,3\",\"Train,bare,30\",\"Train,bare,300\",\"Train,bare,3000\",\"Train,bare,30000\"]}},\"id\":\"d2c05425-4f51-4c0c-b7c6-98fbaadce318\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1211eddf-f659-43d0-b79f-134ff3425b91\",\"type\":\"CategoricalTicker\"},{\"attributes\":{},\"id\":\"1e243dd6-9eaf-4f4e-9636-717da2fd2d7b\",\"type\":\"HelpTool\"},{\"attributes\":{\"tools\":[{\"id\":\"70c653cb-4705-4352-a46e-8a1151226d7b\",\"type\":\"PanTool\"},{\"id\":\"7945d2f2-a0be-4da7-b49b-bafc15c75c5e\",\"type\":\"WheelZoomTool\"},{\"id\":\"4eb5dd1f-e53b-4a97-9e83-39a03985d8a1\",\"type\":\"BoxZoomTool\"},{\"id\":\"2e0213fb-2682-417b-ae1c-bd7ae9e90373\",\"type\":\"SaveTool\"},{\"id\":\"01a6e3b9-ef0a-4a15-be39-7a350e50e69a\",\"type\":\"ResetTool\"},{\"id\":\"1e243dd6-9eaf-4f4e-9636-717da2fd2d7b\",\"type\":\"HelpTool\"},{\"id\":\"15aee8ae-d391-4403-ad0c-4e9d9ac39842\",\"type\":\"PanTool\"},{\"id\":\"64511e6a-87d5-4079-be4b-a618555c84a0\",\"type\":\"WheelZoomTool\"},{\"id\":\"55de4492-34b3-4018-bac8-6a29ea1f5830\",\"type\":\"BoxZoomTool\"},{\"id\":\"16a4fcda-c37e-4556-924f-05a140dfc2ab\",\"type\":\"SaveTool\"},{\"id\":\"464e6f71-ad8b-4912-82b3-0533531c55f2\",\"type\":\"ResetTool\"},{\"id\":\"05fb7596-507f-4d8f-9784-f490db1dd9a8\",\"type\":\"HelpTool\"},{\"id\":\"acda570e-172f-4bb4-89c4-f709eb084aa2\",\"type\":\"PanTool\"},{\"id\":\"cce9c993-8fd5-4bec-9799-363f0d74e7d3\",\"type\":\"WheelZoomTool\"},{\"id\":\"c7b041be-b319-4ecb-a849-2106473c51ee\",\"type\":\"BoxZoomTool\"},{\"id\":\"cff826f0-f551-4ef4-83a6-21a12271dd50\",\"type\":\"SaveTool\"},{\"id\":\"e2578b93-9c64-4d7b-9a08-5687fe8b5da4\",\"type\":\"ResetTool\"},{\"id\":\"676ac94f-5776-4fef-a10f-1a7e11c4d328\",\"type\":\"HelpTool\"}]},\"id\":\"3cd83663-f0db-43a6-8fa4-7f35d9de8ca0\",\"type\":\"ProxyToolbar\"},{\"attributes\":{},\"id\":\"18069087-7902-4e4e-8cb2-5f43521db00f\",\"type\":\"LinearScale\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"4b0b01b5-3f3e-4753-a8a7-55573fa8ddee\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"items\":[{\"id\":\"24aca68b-a554-407d-b64d-a0cb124d5d39\",\"type\":\"LegendItem\"}],\"location\":\"top_left\",\"plot\":{\"id\":\"369bd57b-930f-4449-baab-a997a2b18674\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"8c7e00a1-c489-4c25-812c-1ebaca95c72c\",\"type\":\"Legend\"},{\"attributes\":{\"items\":[{\"id\":\"12101348-1675-4da9-af0c-12bf357d4864\",\"type\":\"LegendItem\"}],\"location\":\"top_left\",\"plot\":{\"id\":\"c81ea69e-7107-4105-811f-df5a180a8923\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"610e4b78-b544-4555-a167-f2330db1ae1a\",\"type\":\"Legend\"},{\"attributes\":{},\"id\":\"70c653cb-4705-4352-a46e-8a1151226d7b\",\"type\":\"PanTool\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"ce111a15-3b86-4dc6-bda0-25b086950898\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"034a7fdd-5e4b-4930-bfda-298dbf269c46\",\"type\":\"BasicTicker\"}},\"id\":\"7935c8db-8ec9-466b-a97c-bb0362a1f5b5\",\"type\":\"Grid\"},{\"attributes\":{\"callback\":null,\"start\":0},\"id\":\"e49ddf77-7e75-4685-93ae-4137e8af3904\",\"type\":\"DataRange1d\"},{\"attributes\":{\"below\":[{\"id\":\"ec38c40b-e860-4181-9594-da57efa614d3\",\"type\":\"CategoricalAxis\"}],\"left\":[{\"id\":\"64b5b67b-953b-498f-be30-0709d8fe4245\",\"type\":\"LinearAxis\"}],\"outline_line_color\":{\"value\":null},\"plot_height\":365,\"plot_width\":488,\"renderers\":[{\"id\":\"ec38c40b-e860-4181-9594-da57efa614d3\",\"type\":\"CategoricalAxis\"},{\"id\":\"393a933b-24ce-448a-b322-af95a29979d5\",\"type\":\"Grid\"},{\"id\":\"64b5b67b-953b-498f-be30-0709d8fe4245\",\"type\":\"LinearAxis\"},{\"id\":\"7935c8db-8ec9-466b-a97c-bb0362a1f5b5\",\"type\":\"Grid\"},{\"id\":\"280ee3c7-a2e7-4ab5-8b4b-5458a9f90337\",\"type\":\"BoxAnnotation\"},{\"id\":\"9662b232-8c9b-4d71-a031-ccc40e98b32c\",\"type\":\"Legend\"},{\"id\":\"ca2f1d40-0280-42cf-81d3-e9d17173fef9\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"d9df53c0-5710-4be2-861a-de4d86710f75\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"c16e18a4-9f16-4fc9-a70c-3aadd06b6b57\",\"type\":\"Toolbar\"},\"toolbar_location\":null,\"x_range\":{\"id\":\"36690f8e-a53c-4228-aabc-5d5094a6e6aa\",\"type\":\"FactorRange\"},\"x_scale\":{\"id\":\"f4d82e7a-ea22-4e06-a228-3e6d4443f9f1\",\"type\":\"CategoricalScale\"},\"y_range\":{\"id\":\"c5267628-aff1-4e54-8c9b-82ca018243c1\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"18069087-7902-4e4e-8cb2-5f43521db00f\",\"type\":\"LinearScale\"}},\"id\":\"ce111a15-3b86-4dc6-bda0-25b086950898\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"plot\":null,\"text\":\"model = NB\"},\"id\":\"7f1ac90c-3383-4da4-a2c0-23d08f62d7e6\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"02b0077c-6d5b-4129-97f3-895112d699b1\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"items\":[{\"id\":\"a10edc1b-1ace-4909-8056-cad9a986a59b\",\"type\":\"LegendItem\"}],\"location\":\"top_left\",\"plot\":{\"id\":\"ce111a15-3b86-4dc6-bda0-25b086950898\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"9662b232-8c9b-4d71-a031-ccc40e98b32c\",\"type\":\"Legend\"},{\"attributes\":{\"below\":[{\"id\":\"a84abc2a-e296-44fe-902a-6c10aaf79164\",\"type\":\"CategoricalAxis\"}],\"left\":[{\"id\":\"dba0f553-7e09-4e7e-8b2c-40c0c907892f\",\"type\":\"LinearAxis\"}],\"outline_line_color\":{\"value\":null},\"plot_height\":365,\"plot_width\":488,\"renderers\":[{\"id\":\"a84abc2a-e296-44fe-902a-6c10aaf79164\",\"type\":\"CategoricalAxis\"},{\"id\":\"969eac38-e1fb-4897-94ea-5e2d72a81fde\",\"type\":\"Grid\"},{\"id\":\"dba0f553-7e09-4e7e-8b2c-40c0c907892f\",\"type\":\"LinearAxis\"},{\"id\":\"2a5c1d7f-2676-460f-9f46-2c98c40f2cb7\",\"type\":\"Grid\"},{\"id\":\"4b0b01b5-3f3e-4753-a8a7-55573fa8ddee\",\"type\":\"BoxAnnotation\"},{\"id\":\"8c7e00a1-c489-4c25-812c-1ebaca95c72c\",\"type\":\"Legend\"},{\"id\":\"a5071050-e9f6-42fc-8d95-3b234e690686\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"d73f31c4-e4fe-44e5-b910-86e7c8e2d1aa\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"892eaacf-47f7-4a8f-8b9c-43657b151363\",\"type\":\"Toolbar\"},\"toolbar_location\":null,\"x_range\":{\"id\":\"305e2d44-4751-4fb1-9bcf-f2aeb5b6fdc3\",\"type\":\"FactorRange\"},\"x_scale\":{\"id\":\"eaeddb2e-f844-4268-9bfa-6cc9f1ff8e38\",\"type\":\"CategoricalScale\"},\"y_range\":{\"id\":\"2a7ceed9-7b12-49a9-89e8-93a0816b78e5\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"47b8d4bf-bc82-4129-96e7-a494bf2a6e54\",\"type\":\"LinearScale\"}},\"id\":\"369bd57b-930f-4449-baab-a997a2b18674\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"children\":[{\"id\":\"51169c21-c0b6-4c1b-853d-033c338506cc\",\"type\":\"Row\"},{\"id\":\"c981e638-10e0-47b5-852c-bd3266a13695\",\"type\":\"Row\"}]},\"id\":\"bd6c89a8-635c-445d-9359-400bb561f971\",\"type\":\"Column\"},{\"attributes\":{\"callback\":null,\"factors\":[\"Test,bare,3\",\"Test,bare,30\",\"Test,bare,300\",\"Test,bare,3000\",\"Test,bare,30000\",\"Train,bare,3\",\"Train,bare,30\",\"Train,bare,300\",\"Train,bare,3000\",\"Train,bare,30000\"],\"range_padding\":0.1},\"id\":\"9b5ecfee-8e7e-43a8-ac85-36ee24a74214\",\"type\":\"FactorRange\"},{\"attributes\":{\"overlay\":{\"id\":\"4b0b01b5-3f3e-4753-a8a7-55573fa8ddee\",\"type\":\"BoxAnnotation\"}},\"id\":\"4eb5dd1f-e53b-4a97-9e83-39a03985d8a1\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"15aee8ae-d391-4403-ad0c-4e9d9ac39842\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"cdb74704-27da-4617-ac11-3c7779a2e8a0\",\"type\":\"CategoricalTickFormatter\"},{\"attributes\":{\"bottom\":{\"expr\":{\"id\":\"fb31333d-0e1b-41f4-862c-825a1c8b2475\",\"type\":\"Stack\"}},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":\"#1f77b4\"},\"top\":{\"expr\":{\"id\":\"d7667075-72d8-4c2a-94e3-bd74fba001f3\",\"type\":\"Stack\"}},\"width\":{\"value\":0.9},\"x\":{\"field\":\"pd_stacked_col\"}},\"id\":\"91a742aa-bb8e-4932-8274-e9cc0641ce38\",\"type\":\"VBar\"},{\"attributes\":{\"label\":{\"value\":\"acc\"},\"renderers\":[{\"id\":\"34b735a5-e0b4-41b6-be99-2a65aa6de6d9\",\"type\":\"GlyphRenderer\"}]},\"id\":\"12101348-1675-4da9-af0c-12bf357d4864\",\"type\":\"LegendItem\"},{\"attributes\":{\"axis_label\":\"mode,t,n\",\"formatter\":{\"id\":\"5f6e3092-1a80-4814-af09-2a2fd0720fb8\",\"type\":\"CategoricalTickFormatter\"},\"major_label_orientation\":1,\"minor_tick_line_color\":{\"value\":null},\"plot\":{\"id\":\"ce111a15-3b86-4dc6-bda0-25b086950898\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"9e3c731b-94fb-4ced-9195-d35e111d106a\",\"type\":\"CategoricalTicker\"}},\"id\":\"ec38c40b-e860-4181-9594-da57efa614d3\",\"type\":\"CategoricalAxis\"},{\"attributes\":{\"plot\":null,\"text\":\"model = LR\"},\"id\":\"d73f31c4-e4fe-44e5-b910-86e7c8e2d1aa\",\"type\":\"Title\"},{\"attributes\":{\"data_source\":{\"id\":\"20a60111-d25a-4b60-83bf-64791b127ae8\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"91a742aa-bb8e-4932-8274-e9cc0641ce38\",\"type\":\"VBar\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"b08626ae-86a0-4f49-a37f-3c95abbf601f\",\"type\":\"VBar\"},\"selection_glyph\":null,\"view\":{\"id\":\"817399fd-58e0-4daa-8b9d-8a3773c0284f\",\"type\":\"CDSView\"}},\"id\":\"a5071050-e9f6-42fc-8d95-3b234e690686\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"4f86bed3-701a-4373-ad60-53f0d07c7802\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"bottom\":{\"expr\":{\"id\":\"d1cc8f78-ff34-41fa-bd76-edf6fc76e590\",\"type\":\"Stack\"}},\"fill_color\":{\"value\":\"#2ca02c\"},\"line_color\":{\"value\":\"#2ca02c\"},\"top\":{\"expr\":{\"id\":\"44168190-6d9f-487b-91a4-5b93791c57e0\",\"type\":\"Stack\"}},\"width\":{\"value\":0.9},\"x\":{\"field\":\"pd_stacked_col\"}},\"id\":\"08a0f870-072c-4d46-85cc-ad8e116a3fba\",\"type\":\"VBar\"},{\"attributes\":{},\"id\":\"64511e6a-87d5-4079-be4b-a618555c84a0\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"grid_line_color\":{\"value\":null},\"plot\":{\"id\":\"c81ea69e-7107-4105-811f-df5a180a8923\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1211eddf-f659-43d0-b79f-134ff3425b91\",\"type\":\"CategoricalTicker\"}},\"id\":\"d553df30-0188-40bd-ae8b-2cd42097de09\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"6a096a01-4943-4d53-a119-2b1cb3babcab\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"callback\":null,\"factors\":[\"Test,bare,3\",\"Test,bare,30\",\"Test,bare,300\",\"Test,bare,3000\",\"Test,bare,30000\",\"Train,bare,3\",\"Train,bare,30\",\"Train,bare,300\",\"Train,bare,3000\",\"Train,bare,30000\"],\"range_padding\":0.1},\"id\":\"36690f8e-a53c-4228-aabc-5d5094a6e6aa\",\"type\":\"FactorRange\"},{\"attributes\":{},\"id\":\"676ac94f-5776-4fef-a10f-1a7e11c4d328\",\"type\":\"HelpTool\"},{\"attributes\":{\"children\":[{\"id\":\"369bd57b-930f-4449-baab-a997a2b18674\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"id\":\"c81ea69e-7107-4105-811f-df5a180a8923\",\"subtype\":\"Figure\",\"type\":\"Plot\"}]},\"id\":\"51169c21-c0b6-4c1b-853d-033c338506cc\",\"type\":\"Row\"},{\"attributes\":{},\"id\":\"cff826f0-f551-4ef4-83a6-21a12271dd50\",\"type\":\"SaveTool\"},{\"attributes\":{\"overlay\":{\"id\":\"4f86bed3-701a-4373-ad60-53f0d07c7802\",\"type\":\"BoxAnnotation\"}},\"id\":\"55de4492-34b3-4018-bac8-6a29ea1f5830\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"below\":[{\"id\":\"07489ba8-6994-467a-a4cc-1888870accb0\",\"type\":\"CategoricalAxis\"}],\"left\":[{\"id\":\"961bbe31-bcb8-45f1-9cab-300d39271f85\",\"type\":\"LinearAxis\"}],\"outline_line_color\":{\"value\":null},\"plot_height\":365,\"plot_width\":488,\"renderers\":[{\"id\":\"07489ba8-6994-467a-a4cc-1888870accb0\",\"type\":\"CategoricalAxis\"},{\"id\":\"d553df30-0188-40bd-ae8b-2cd42097de09\",\"type\":\"Grid\"},{\"id\":\"961bbe31-bcb8-45f1-9cab-300d39271f85\",\"type\":\"LinearAxis\"},{\"id\":\"50dc2479-aca3-45e0-9a9d-3f7f4ecc9bb9\",\"type\":\"Grid\"},{\"id\":\"4f86bed3-701a-4373-ad60-53f0d07c7802\",\"type\":\"BoxAnnotation\"},{\"id\":\"610e4b78-b544-4555-a167-f2330db1ae1a\",\"type\":\"Legend\"},{\"id\":\"34b735a5-e0b4-41b6-be99-2a65aa6de6d9\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"7f1ac90c-3383-4da4-a2c0-23d08f62d7e6\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"a06dcb43-e848-46bc-ba96-261c5db46d4b\",\"type\":\"Toolbar\"},\"toolbar_location\":null,\"x_range\":{\"id\":\"9b5ecfee-8e7e-43a8-ac85-36ee24a74214\",\"type\":\"FactorRange\"},\"x_scale\":{\"id\":\"15342c33-cd3c-4f02-b4fe-51e84314840b\",\"type\":\"CategoricalScale\"},\"y_range\":{\"id\":\"e49ddf77-7e75-4685-93ae-4137e8af3904\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"da904b13-d4d7-4c42-8e98-9bada2d50cf9\",\"type\":\"LinearScale\"}},\"id\":\"c81ea69e-7107-4105-811f-df5a180a8923\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"280ee3c7-a2e7-4ab5-8b4b-5458a9f90337\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"callback\":null,\"factors\":[\"Test,bare,3\",\"Test,bare,30\",\"Test,bare,300\",\"Test,bare,3000\",\"Test,bare,30000\",\"Train,bare,3\",\"Train,bare,30\",\"Train,bare,300\",\"Train,bare,3000\",\"Train,bare,30000\"],\"range_padding\":0.1},\"id\":\"305e2d44-4751-4fb1-9bcf-f2aeb5b6fdc3\",\"type\":\"FactorRange\"},{\"attributes\":{\"callback\":null,\"start\":0},\"id\":\"2a7ceed9-7b12-49a9-89e8-93a0816b78e5\",\"type\":\"DataRange1d\"},{\"attributes\":{\"grid_line_color\":{\"value\":null},\"plot\":{\"id\":\"ce111a15-3b86-4dc6-bda0-25b086950898\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"9e3c731b-94fb-4ced-9195-d35e111d106a\",\"type\":\"CategoricalTicker\"}},\"id\":\"393a933b-24ce-448a-b322-af95a29979d5\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"15342c33-cd3c-4f02-b4fe-51e84314840b\",\"type\":\"CategoricalScale\"},{\"attributes\":{\"source\":{\"id\":\"cb3831ab-198a-4ce9-8bc6-607e6ee0b6f1\",\"type\":\"ColumnDataSource\"}},\"id\":\"5ce9090c-8f98-43a5-8d57-cf1b6db8a014\",\"type\":\"CDSView\"}],\"root_ids\":[\"ef9de844-3f6f-4cdf-a7bb-a03e3724c7f4\"]},\"title\":\"Bokeh Application\",\"version\":\"0.12.13\"}}';\n          var render_items = [{\"docid\":\"dee38daa-80e3-47fa-a0f4-be58702c77f6\",\"elementid\":\"629f8c75-fd99-44d2-a5ab-d77de2b0b98f\",\"modelid\":\"ef9de844-3f6f-4cdf-a7bb-a03e3724c7f4\"}];\n          root.Bokeh.embed.embed_items(docs_json, render_items);\n        \n          }\n          if (root.Bokeh !== undefined) {\n            embed_document(root);\n          } else {\n            var attempts = 0;\n            var timer = setInterval(function(root) {\n              if (root.Bokeh !== undefined) {\n                embed_document(root);\n                clearInterval(timer);\n              }\n              attempts++;\n              if (attempts > 100) {\n                console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\")\n                clearInterval(timer);\n              }\n            }, 10, root)\n          }\n        })(window);\n      });\n    };\n    if (document.readyState != \"loading\") fn();\n    else document.addEventListener(\"DOMContentLoaded\", fn);\n  })();\n<\\/script>`\n                                var chartscript = el.childNodes[1]\n                                var s = document.createElement(\"script\")\n                                s.innerHTML = chartscript.innerHTML\n                                d.parentNode.insertBefore(s, d)\n                            }\n                        }\n                    }\n                    if (!window.Bokeh && !window.autoload){\n                        window.autoload=true;\n                        \n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = 1;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.13.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));\n                    }\n                    setChartScript()\n                    </script>", 
                        "text/plain": "<IPython.core.display.HTML object>"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {
                "pixiedust": {
                    "displayParams": {
                        "no_margin": "true", 
                        "orientation": "vertical", 
                        "title": "Accuracy by model,type,and mode.", 
                        "chartsize": "80", 
                        "dynamicfilter": "{}", 
                        "aggregation": "AVG", 
                        "clusterby": "model", 
                        "handlerId": "barChart", 
                        "valueFields": "acc", 
                        "rendererId": "bokeh", 
                        "sortby": "Keys ASC", 
                        "charttype": "subplots", 
                        "keyFields": "mode,t,n", 
                        "legend": "true"
                    }
                }
            }
        }
    ], 
    "nbformat": 4, 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "pygments_lexer": "ipython3", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }
}